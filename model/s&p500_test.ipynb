{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stock data.\n",
    "file_path = '..\\data\\s&p500\\s&p500_2016to2022_stock_data.csv'\n",
    "stock_data = pd.read_csv(file_path, index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>2012.660034</td>\n",
       "      <td>40.689999</td>\n",
       "      <td>40.910000</td>\n",
       "      <td>152.240005</td>\n",
       "      <td>26.337500</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>85.239998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.930000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>...</td>\n",
       "      <td>35.700001</td>\n",
       "      <td>77.459999</td>\n",
       "      <td>58.860001</td>\n",
       "      <td>27.140976</td>\n",
       "      <td>36.080002</td>\n",
       "      <td>51.912292</td>\n",
       "      <td>98.844658</td>\n",
       "      <td>66.489998</td>\n",
       "      <td>26.709999</td>\n",
       "      <td>47.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>2016.709961</td>\n",
       "      <td>40.549999</td>\n",
       "      <td>40.520000</td>\n",
       "      <td>151.199997</td>\n",
       "      <td>25.677500</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.919998</td>\n",
       "      <td>23.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>36.060001</td>\n",
       "      <td>78.120003</td>\n",
       "      <td>60.060001</td>\n",
       "      <td>27.088274</td>\n",
       "      <td>36.070000</td>\n",
       "      <td>51.782890</td>\n",
       "      <td>100.902916</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>26.420000</td>\n",
       "      <td>48.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>1990.260010</td>\n",
       "      <td>40.730000</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>147.199997</td>\n",
       "      <td>25.174999</td>\n",
       "      <td>57.380001</td>\n",
       "      <td>85.300003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.560001</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.439999</td>\n",
       "      <td>77.470001</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>26.745718</td>\n",
       "      <td>35.619999</td>\n",
       "      <td>51.416248</td>\n",
       "      <td>101.339806</td>\n",
       "      <td>62.230000</td>\n",
       "      <td>25.650000</td>\n",
       "      <td>48.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>1943.089966</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>40.450001</td>\n",
       "      <td>148.830002</td>\n",
       "      <td>24.112499</td>\n",
       "      <td>57.209999</td>\n",
       "      <td>81.919998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.540001</td>\n",
       "      <td>23.046667</td>\n",
       "      <td>...</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>76.230003</td>\n",
       "      <td>58.669998</td>\n",
       "      <td>26.007904</td>\n",
       "      <td>34.700001</td>\n",
       "      <td>49.662113</td>\n",
       "      <td>99.009712</td>\n",
       "      <td>59.410000</td>\n",
       "      <td>24.879999</td>\n",
       "      <td>46.560001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>1922.030029</td>\n",
       "      <td>38.590000</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>145.559998</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>55.650002</td>\n",
       "      <td>84.580002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.669998</td>\n",
       "      <td>22.806667</td>\n",
       "      <td>...</td>\n",
       "      <td>36.180000</td>\n",
       "      <td>74.690002</td>\n",
       "      <td>56.990002</td>\n",
       "      <td>25.270092</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>48.986340</td>\n",
       "      <td>98.592232</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>45.880001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC          A        AAL         AAP       AAPL  \\\n",
       "date                                                                   \n",
       "2016-01-04  2012.660034  40.689999  40.910000  152.240005  26.337500   \n",
       "2016-01-05  2016.709961  40.549999  40.520000  151.199997  25.677500   \n",
       "2016-01-06  1990.260010  40.730000  41.230000  147.199997  25.174999   \n",
       "2016-01-07  1943.089966  39.000000  40.450001  148.830002  24.112499   \n",
       "2016-01-08  1922.030029  38.590000  40.369999  145.559998  24.240000   \n",
       "\n",
       "                 ABBV       ABMD  ABS        ABT       ACGL  ...        XEL  \\\n",
       "date                                                         ...              \n",
       "2016-01-04  57.610001  85.239998  NaN  42.930000  22.950001  ...  35.700001   \n",
       "2016-01-05  57.369999  85.000000  NaN  42.919998  23.033333  ...  36.060001   \n",
       "2016-01-06  57.380001  85.300003  NaN  42.560001  23.070000  ...  36.439999   \n",
       "2016-01-07  57.209999  81.919998  NaN  41.540001  23.046667  ...  36.580002   \n",
       "2016-01-08  55.650002  84.580002  NaN  40.669998  22.806667  ...  36.180000   \n",
       "\n",
       "                  XOM       XRAY        XRX        XYL        YUM         ZBH  \\\n",
       "date                                                                            \n",
       "2016-01-04  77.459999  58.860001  27.140976  36.080002  51.912292   98.844658   \n",
       "2016-01-05  78.120003  60.060001  27.088274  36.070000  51.782890  100.902916   \n",
       "2016-01-06  77.470001  59.189999  26.745718  35.619999  51.416248  101.339806   \n",
       "2016-01-07  76.230003  58.669998  26.007904  34.700001  49.662113   99.009712   \n",
       "2016-01-08  74.690002  56.990002  25.270092  34.369999  48.986340   98.592232   \n",
       "\n",
       "                 ZBRA       ZION        ZTS  \n",
       "date                                         \n",
       "2016-01-04  66.489998  26.709999  47.270000  \n",
       "2016-01-05  64.820000  26.420000  48.009998  \n",
       "2016-01-06  62.230000  25.650000  48.020000  \n",
       "2016-01-07  59.410000  24.879999  46.560001  \n",
       "2016-01-08  59.250000  24.600000  45.880001  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-19</th>\n",
       "      <td>-0.009008</td>\n",
       "      <td>-0.015740</td>\n",
       "      <td>-0.025761</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002993</td>\n",
       "      <td>-0.008029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>-0.071099</td>\n",
       "      <td>-0.013011</td>\n",
       "      <td>-0.007652</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>-0.020930</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.008791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-20</th>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>-0.010788</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000938</td>\n",
       "      <td>0.028081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.042523</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>-0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.039904</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.014573</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>0.014930</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.017197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22</th>\n",
       "      <td>-0.014452</td>\n",
       "      <td>-0.007196</td>\n",
       "      <td>-0.036071</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.008049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005397</td>\n",
       "      <td>-0.020174</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>-0.012795</td>\n",
       "      <td>-0.012056</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.002282</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ^GSPC         A       AAL       AAP      AAPL      ABBV  \\\n",
       "date                                                                     \n",
       "2022-12-19 -0.009008 -0.015740 -0.025761  0.005280 -0.015910  0.006294   \n",
       "2022-12-20  0.001037  0.006669  0.004006 -0.010788 -0.000529 -0.005635   \n",
       "2022-12-21  0.014868  0.014602  0.039904  0.020878  0.023809  0.010151   \n",
       "2022-12-22 -0.014452 -0.007196 -0.036071 -0.001476 -0.023773  0.006535   \n",
       "2022-12-23  0.005868  0.001476  0.011943  0.008446 -0.002798 -0.001041   \n",
       "\n",
       "                ABMD  ABS       ABT      ACGL  ...       XEL       XOM  \\\n",
       "date                                           ...                       \n",
       "2022-12-19  0.000787  0.0 -0.002993 -0.008029  ... -0.007437  0.004489   \n",
       "2022-12-20 -0.001337  0.0 -0.000938  0.028081  ...  0.001297  0.014453   \n",
       "2022-12-21  0.000604  0.0  0.015494  0.017995  ...  0.013239  0.012841   \n",
       "2022-12-22  0.000000  0.0 -0.001017 -0.008049  ... -0.005397 -0.020174   \n",
       "2022-12-23  0.000000  0.0  0.001389  0.008433  ...  0.012852  0.026445   \n",
       "\n",
       "                XRAY       XRX       XYL       YUM       ZBH      ZBRA  \\\n",
       "date                                                                     \n",
       "2022-12-19  0.002621 -0.071099 -0.013011 -0.007652 -0.004937 -0.020930   \n",
       "2022-12-20  0.009150  0.042523 -0.001751  0.001636  0.003761  0.014115   \n",
       "2022-12-21  0.014573  0.009517  0.026411  0.001478  0.013155  0.014930   \n",
       "2022-12-22  0.004788 -0.012795 -0.012056  0.000311 -0.002282 -0.013275   \n",
       "2022-12-23  0.011118 -0.003411 -0.000728  0.000621 -0.000789  0.002869   \n",
       "\n",
       "                ZION       ZTS  \n",
       "date                            \n",
       "2022-12-19 -0.007163 -0.008791  \n",
       "2022-12-20  0.008526 -0.005028  \n",
       "2022-12-21  0.031216  0.017197  \n",
       "2022-12-22  0.014925  0.000759  \n",
       "2022-12-23  0.003521  0.005033  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate daily returns\n",
    "stock_returns = stock_data.pct_change().dropna(how='all')\n",
    "stock_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_returns['^GSPC'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment setup\n",
    "- daily return을 기준으로 index tracking 설정\n",
    "- 월별 리벨런싱 가정\n",
    "- 2006/01/01 ~ 2022-12/30\n",
    "- k act: 10% 20% 30% 40% 50% - 전체 주식의 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gurobi with adaptive loss 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-07-25\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Model fingerprint: 0xb1b4833e\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "Presolve time: 0.02s\n",
      "Presolved: 2 rows, 2 columns, 4 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.0000000e+30   3.000000e+30   2.000000e+00      0s\n",
      "       2    3.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.04 seconds (0.00 work units)\n",
      "Optimal objective  3.000000000e+00\n",
      "Iteration 0, x: 2.0\n",
      "Iteration 0, y: 1.0\n",
      "Iteration 0, Obj: 3.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [3e+00, 3e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    9.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  9.000000000e+00\n",
      "Iteration 1, x: 2.0\n",
      "Iteration 1, y: 1.0\n",
      "Iteration 1, Obj: 9.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [9e+00, 9e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.7000000e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  2.700000000e+01\n",
      "Iteration 2, x: 2.0\n",
      "Iteration 2, y: 1.0\n",
      "Iteration 2, Obj: 27.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [3e+01, 3e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    8.1000000e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  8.100000000e+01\n",
      "Iteration 3, x: 2.0\n",
      "Iteration 3, y: 1.0\n",
      "Iteration 3, Obj: 81.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [8e+01, 8e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.4300000e+02   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  2.430000000e+02\n",
      "Iteration 4, x: 2.0\n",
      "Iteration 4, y: 1.0\n",
      "Iteration 4, Obj: 243.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+02, 2e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    7.2900000e+02   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  7.290000000e+02\n",
      "Iteration 5, x: 2.0\n",
      "Iteration 5, y: 1.0\n",
      "Iteration 5, Obj: 729.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [7e+02, 7e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.1870000e+03   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.03 seconds (0.00 work units)\n",
      "Optimal objective  2.187000000e+03\n",
      "Iteration 6, x: 2.0\n",
      "Iteration 6, y: 1.0\n",
      "Iteration 6, Obj: 2187.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+03, 2e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    6.5610000e+03   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.03 seconds (0.00 work units)\n",
      "Optimal objective  6.561000000e+03\n",
      "Iteration 7, x: 2.0\n",
      "Iteration 7, y: 1.0\n",
      "Iteration 7, Obj: 6561.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [7e+03, 7e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.9683000e+04   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  1.968300000e+04\n",
      "Iteration 8, x: 2.0\n",
      "Iteration 8, y: 1.0\n",
      "Iteration 8, Obj: 19683.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+04, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    5.9049000e+04   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  5.904900000e+04\n",
      "Iteration 9, x: 2.0\n",
      "Iteration 9, y: 1.0\n",
      "Iteration 9, Obj: 59049.0\n",
      "Final x: 2.0\n",
      "Final y: 1.0\n",
      "Final Obj: 59049.0\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# 데이터 초기화\n",
    "max_iterations = 10  # 최대 반복 횟수\n",
    "epsilon = 1e-6  # 수렴 조건\n",
    "w = 1.0  # 초기 가중치\n",
    "previous_obj_value = float('inf')  # 초기 Objective Function 값\n",
    "\n",
    "# 모델 생성\n",
    "model = gp.Model(\"adaptive_weights\")\n",
    "\n",
    "# 변수 추가\n",
    "x = model.addVar(name=\"x\")\n",
    "y = model.addVar(name=\"y\")\n",
    "\n",
    "# 제약 조건 추가\n",
    "model.addConstr(x + 2 * y <= 4, \"c0\")\n",
    "model.addConstr(2 * x + y <= 5, \"c1\")\n",
    "\n",
    "# 반복 프로세스\n",
    "for iteration in range(max_iterations):\n",
    "    # 목표 함수 설정\n",
    "    model.setObjective(w * (x + y), GRB.MAXIMIZE)\n",
    "    \n",
    "    # 최적화 수행\n",
    "    model.optimize()\n",
    "    \n",
    "    # 결과 출력\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.SUBOPTIMAL:\n",
    "        for v in model.getVars():\n",
    "            print(f'Iteration {iteration}, {v.varName}: {v.x}')\n",
    "        print(f'Iteration {iteration}, Obj: {model.objVal}')\n",
    "        \n",
    "        # 가중치 업데이트 (예: 목표 함수 값의 절대값을 가중치로 사용)\n",
    "        new_w = abs(model.objVal)\n",
    "        \n",
    "        # 수렴 확인\n",
    "        if abs(previous_obj_value - model.objVal) < epsilon:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # 업데이트된 가중치 및 이전 목표 함수 값 갱신\n",
    "        w = new_w\n",
    "        previous_obj_value = model.objVal\n",
    "    else:\n",
    "        print(f\"Optimization was stopped at iteration {iteration}\")\n",
    "        break\n",
    "\n",
    "# 최종 결과 출력\n",
    "if model.status == GRB.OPTIMAL or model.status == GRB.SUBOPTIMAL:\n",
    "    for v in model.getVars():\n",
    "        print(f'Final {v.varName}: {v.x}')\n",
    "    print(f'Final Obj: {model.objVal}')\n",
    "else:\n",
    "    print(\"최적 해를 찾지 못했습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(X, y, kact, time_limit=1200):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) <= kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_stocks = stock_returns.drop(columns=['^GSPC'])\n",
    "stock_index = stock_returns['^GSPC']\n",
    "\n",
    "train_data = stock_stocks.iloc[:250]\n",
    "\n",
    "# Filter out columns with NaN values in the current window\n",
    "valid_assets_train = train_data.dropna(axis=1)\n",
    "valid_assets = valid_assets_train.columns.intersection(valid_assets_train.columns)\n",
    "\n",
    "X_train = valid_assets_train[valid_assets].values\n",
    "y_train = stock_index.iloc[:250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\cvxpy\\problems\\problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # CARD\n",
    "beta_card = card(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_card > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALASSO Algorithm\n",
    "- make initial beta using OLS\n",
    "- can not find propal lambda in the context\n",
    "- FIX!: ALASSO solution is always converge to 1,0,0,0 -> shrinking is too strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def alasso(X, y, kact, time_limit=1200, lambdas=1):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Initial Lasso to get initial weights\n",
    "    lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "    lasso.fit(X, y)\n",
    "    beta_init = lasso.coef_\n",
    "    \n",
    "    # Adaptive weights\n",
    "    weights = 1 / (np.abs(beta_init) + 1e-6)\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + lambdas * cp.sum(weights @ cp.abs(beta)))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) == kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALASSO\n",
    "beta_alasso = alasso(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_alasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted LASSO- SLOPE\n",
    "detail is from Sparse index clones via the sorted l1-Norm\n",
    "SLOPE—ADAPTIVE VARIABLE SELECTION VIA CONVEX OPTIMIZATION\n",
    "\n",
    "- initial guess beta를 가지고 추정 시작\n",
    "- 이후 update\n",
    "- lambda of model: aplha(=sigma of model)(1-i*theta)~ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the lambda sequence\n",
    "def new_lambda(beta_value, alpha, theta, p):\n",
    "    # Compute the ranks of the absolute values of beta_value\n",
    "    ranks = np.argsort(np.argsort(-np.abs(beta_value))) + 1\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (rank * theta / (2 * p))) for rank in ranks])\n",
    "    # lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * p))) for i in range(1, p + 1)])\n",
    "    return lambdas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(X, y, kact, alpha=1.0, theta=0.1, tol=1e-06, max_iter=10, time_limit=1200, add_loss=0, seed=42):\n",
    "    \"\"\"\n",
    "    Solve the SLOPE optimization problem using Gurobi with an activation constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like, shape (T, K)\n",
    "        The return matrix of benchmark constituents.\n",
    "    y : array-like, shape (T,)\n",
    "        The benchmark returns.\n",
    "    kact : int\n",
    "        Number of active variables (non-zero coefficients) allowed.\n",
    "    alpha : float, optional\n",
    "        Regularization parameter for the lambda sequence.\n",
    "    theta : float, optional\n",
    "        Decay rate for the lambda sequence.\n",
    "    \"\"\"\n",
    "    # Number of samples and features\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    for _ in range(max_iter):\n",
    "        m.reset()   \n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta + add_loss\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        beta_value = beta.X\n",
    "        # 결과 출력\n",
    "        if m.status == GRB.OPTIMAL or m.status == GRB.SUBOPTIMAL:\n",
    "            beta_value = beta.X\n",
    "            new_weights = np.array(new_lambda(beta_value, alpha, theta, p))\n",
    "            weights = new_weights\n",
    "            \n",
    "            if np.linalg.norm(new_weights - weights) < tol:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    m.dispose()        \n",
    "    return beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0xe44256d2\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.32s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3826    1.0000117e+00   9.443133e+00   0.000000e+00      5s\n",
      "    8437    1.0000001e+00   0.000000e+00   0.000000e+00      9s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8437 iterations, 8.74 seconds (4.11 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   86    1.00015    1.00000  0.01%     -    9s\n",
      "H    0     0                       1.0000084    1.00000  0.00%     -   11s\n",
      "\n",
      "Explored 1 nodes (8437 simplex iterations) in 11.46 seconds (4.99 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00001 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000008393543e+00, best bound 1.000000096043e+00, gap 0.0008%\n"
     ]
    }
   ],
   "source": [
    "# SLOPE\n",
    "beta_slope = slope(X_train, y_train, kact=20, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_slope > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOPE-SLC\n",
    "1. Sorted LASSO의 변형 형태\n",
    "2. compute for each group the median partial correlation of consituents and keep only groups which are including 75th percent quantile for the equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_partial_correlation(X, y):\n",
    "#     # Use LassoLarsIC to find significant features\n",
    "#     model = LassoLarsIC(criterion='bic')\n",
    "#     model.fit(X, y)\n",
    "#     active_features = np.where(model.coef_ != 0)[0]\n",
    "    \n",
    "#     partial_corr = np.zeros(X.shape[1])\n",
    "#     for i in active_features:\n",
    "#         residual_y = y - model.predict(X[:, active_features])\n",
    "#         residual_x = X[:, i] - model.predict(X[:, active_features])\n",
    "#         partial_corr[i] = np.corrcoef(residual_y, residual_x)[0, 1]\n",
    "    \n",
    "#     return partial_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def slope_slc(X, y, kact, alpha=1.0, theta=0.1, tol=1e-06, max_iter=10, time_limit=1200, seed=42):\n",
    "    \n",
    "#     # Step 1: Solve SLOPE\n",
    "#     beta_initial = slope(X, y, alpha, theta, tol, max_iter, time_limit, seed)\n",
    "    \n",
    "    \n",
    "#     # Step 2: Compute partial correlation for each asset\n",
    "#     partial_corr = compute_partial_correlation(X, y)\n",
    "    \n",
    "#     # Step 3: Select groups based on median partial correlation\n",
    "#     median_corr = np.median(partial_corr)\n",
    "#     threshold = np.percentile(partial_corr, 75)\n",
    "#     active_indices = np.where(partial_corr >= threshold)[0]\n",
    "    \n",
    "#     # Step 4: Rescale SLOPE estimates to sum to 1\n",
    "#     beta_rescaled = np.zeros_like(beta_initial)\n",
    "#     beta_rescaled[active_indices] = beta_initial[active_indices]\n",
    "#     beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "#     # Step 5: Ensure the number of active weights is less than or equal to kact\n",
    "#     if np.sum(beta_rescaled > 0) > kact:\n",
    "#         sorted_indices = np.argsort(beta_rescaled)[::-1]\n",
    "#         beta_rescaled[sorted_indices[kact:]] = 0\n",
    "#         beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "#     return beta_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SLOPE-SLC\n",
    "# beta_slope_slc = slope_slc(X_train, y_train, kact=20, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_negative_count = np.sum(beta_slope_slc > 0)\n",
    "# non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSW_LASSO\n",
    "detail is from High-dimensional Sprase index tracking based on a multi-step coonvex optimization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msw_lasso(X, y, kact, max_iter=10, tol=1e-12, penalty='MCP', a=2.5, time_limit = 1200, add_loss=0, seed=42):\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    \n",
    "    def p_lambda(beta_j, lam, a):\n",
    "        #MCP: b, a =2.5\n",
    "        #SCAD: a=3.7\n",
    "        #log-M: epsilon = 1.67*10^-5\n",
    "        #lq: q=0.1\n",
    "        if penalty == 'MCP':\n",
    "            b = a \n",
    "            return lam * beta_j - (beta_j**2) / (2 * b) if beta_j <= b * lam else (b * lam**2) / 2\n",
    "        elif penalty == 'SCAD':\n",
    "            if beta_j <= lam:\n",
    "                return lam * beta_j\n",
    "            elif beta_j <= a * lam:\n",
    "                return (-beta_j**2 + 2 * a * lam * beta_j - lam**2) / (2 * (a - 1))\n",
    "            else:\n",
    "                return (a + 1) * lam**2 / 2\n",
    "        elif penalty == 'log-M':\n",
    "            eps = a\n",
    "            return lam * np.log(1+np.abs(beta_j)/eps) / np.log(1+(1/eps))\n",
    "        elif penalty == 'lq':\n",
    "            q = a \n",
    "            return lam * (abs(beta_j) **q) \n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        m.reset()   \n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta + add_loss\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        beta_value = beta.X\n",
    "        # 결과 출력\n",
    "        if m.status == GRB.OPTIMAL or m.status == GRB.SUBOPTIMAL:\n",
    "            beta_value = beta.X\n",
    "            new_weights = np.array([abs(p_lambda(beta_value[j], 1, a)) for j in range(p)])\n",
    "            weights = new_weights\n",
    "            \n",
    "            if np.linalg.norm(new_weights - weights) < tol:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    m.dispose()         \n",
    "    return beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0xe44256d2\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.35s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3342    1.0000056e+00   7.215136e+00   0.000000e+00      5s\n",
      "    8437    1.0000001e+00   0.000000e+00   0.000000e+00     10s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8437 iterations, 9.20 seconds (4.11 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   86    1.00015    1.00000  0.01%     -    9s\n",
      "H    0     0                       1.0000084    1.00000  0.00%     -   11s\n",
      "\n",
      "Explored 1 nodes (8437 simplex iterations) in 11.83 seconds (4.99 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00001 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000008393543e+00, best bound 1.000000096043e+00, gap 0.0008%\n"
     ]
    }
   ],
   "source": [
    "# # msw_lasso\n",
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=20, penalty='MCP', a=2.5, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x3808f38d\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.21s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3330    1.0000035e+00   3.467845e+00   0.000000e+00      5s\n",
      "    8760    1.0000001e+00   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 8.15 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    9s\n",
      "H    0     0                       1.0000167    1.00000  0.00%     -   10s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 10.71 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016680157e+00, best bound 1.000000099790e+00, gap 0.0017%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='SCAD', a=3.7, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x3808f38d\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.20s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3739    9.9993730e-01   1.254121e-01   0.000000e+00      5s\n",
      "    8760    1.0000001e+00   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 8.03 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    8s\n",
      "H    0     0                       1.0000167    1.00000  0.00%     -    9s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 9.62 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016680157e+00, best bound 1.000000099790e+00, gap 0.0017%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='log-M', a=1.67*(10**-5), max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x3808f38d\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.33s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3934    9.9993660e-01   1.002818e+00   0.000000e+00      5s\n",
      "    8760    1.0000001e+00   0.000000e+00   0.000000e+00      7s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 6.53 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    7s\n",
      "H    0     0                       1.0000167    1.00000  0.00%     -    8s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 9.00 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016680157e+00, best bound 1.000000099790e+00, gap 0.0017%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='lq', a=0.1, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest\n",
    "## Experiment result \n",
    "- Turn over 비용\n",
    "- Tracking error(for out of sample)\n",
    "- Computing time(running time second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(X, y, beta):\n",
    "    tracking_error = np.sqrt(np.mean((y - X @ beta)**2))\n",
    "    turnover = np.sum(np.abs(beta[1:] - beta[:-1])) / len(beta)\n",
    "    return tracking_error, turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_backtest(stock_returns, stock_index, train_window, test_window, kact, max_iter=10, time_limit=60):\n",
    "    results = {'CARD': [], 'ALASSO': [], 'SLOPE': [], 'MSW-LASSO-SCAD': [],'MSW-LASSO-MCP': [],'MSW-LASSO-LOGM': [],'MSW-LASSO-lq': [], }\n",
    "    n = len(stock_returns)\n",
    "    \n",
    "    for start in range(0, n - train_window - test_window + 1, test_window):\n",
    "        train_data = stock_returns.iloc[start:start + train_window]\n",
    "        test_data = stock_returns.iloc[start + train_window:start + train_window + test_window]\n",
    "    \n",
    "        # Filter out columns with NaN values in the current window\n",
    "        valid_assets_train = train_data.dropna(axis=1)\n",
    "        valid_assets_test = test_data.dropna(axis=1)\n",
    "        valid_assets = valid_assets_train.columns.intersection(valid_assets_test.columns)\n",
    "        \n",
    "        X_train = valid_assets_train[valid_assets].values\n",
    "        y_train = stock_index.iloc[start:start + train_window].values\n",
    "        \n",
    "        X_test = valid_assets_test[valid_assets].values\n",
    "        y_test = stock_index.iloc[start + train_window:start + train_window + test_window].values\n",
    "        # Skip if no valid assets are available\n",
    "        if X_train.shape[1] == 0 or X_test.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # # CARD\n",
    "        beta_card = card(X_train, y_train, kact, time_limit=time_limit)\n",
    "        te_card, to_card = evaluate_portfolio(X_test, y_test, beta_card)\n",
    "        results['CARD'].append({'date': stock_returns.index[start + train_window], 'te': te_card, 'to': to_card})\n",
    "        \n",
    "        # ALASSO\n",
    "        beta_alasso = alasso(X_train, y_train, kact, time_limit=time_limit)\n",
    "        te_alasso, to_alasso = evaluate_portfolio(X_test, y_test, beta_alasso)\n",
    "        results['ALASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_alasso, 'to': to_alasso})\n",
    "        \n",
    "        #SLOPE\n",
    "        beta_slope = slope(X_train, y_train, kact, max_iter=max_iter, time_limit=time_limit)\n",
    "        te_slope_slc, to_slope_slc = evaluate_portfolio(X_test, y_test, beta_slope)\n",
    "        results['SLOPE'].append({'date': stock_returns.index[start + train_window], 'te': te_slope_slc, 'to': to_slope_slc})\n",
    "        \n",
    "        # MSW-LASSO -SCAD\n",
    "        beta_msw_lasso_scad = msw_lasso(X_train, y_train, kact=kact, penalty='SCAD', a=3.7, max_iter=max_iter, time_limit=time_limit)\n",
    "        te_msw_lasso_scad, to_msw_lasso_scad = evaluate_portfolio(X_test, y_test, beta_msw_lasso_scad)\n",
    "        results['MSW-LASSO-SCAD'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso_scad, 'to': to_msw_lasso_scad})\n",
    "        \n",
    "        # MSW-LASSO -MCP\n",
    "        beta_msw_lasso_mcp = msw_lasso(X_train, y_train, kact=kact, penalty='MCP', a=2.5, max_iter=max_iter, time_limit=time_limit)\n",
    "        te_msw_lasso_mcp, to_msw_lasso_mcp = evaluate_portfolio(X_test, y_test, beta_msw_lasso_mcp)\n",
    "        results['MSW-LASSO-MCP'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso_mcp, 'to': to_msw_lasso_mcp})\n",
    "\n",
    "        # MSW-LASSO-log-M\n",
    "        beta_msw_lasso_logM = msw_lasso(X_train, y_train, kact=kact, penalty='log-M', a=1.67*10**(-5), max_iter=max_iter, time_limit=time_limit)\n",
    "        te_msw_lasso_logM, to_msw_lasso_logM = evaluate_portfolio(X_test, y_test, beta_msw_lasso_logM)\n",
    "        results['MSW-LASSO-LOGM'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso_logM, 'to': to_msw_lasso_logM})\n",
    "\n",
    "        # MSW-LASSO-lq\n",
    "        beta_msw_lasso_lq = msw_lasso(X_train, y_train, kact=kact, penalty='lq', a=0.1, max_iter=max_iter, time_limit=time_limit)\n",
    "        te_msw_lasso_lq, to_msw_lasso_lq = evaluate_portfolio(X_test, y_test, beta_msw_lasso_lq)\n",
    "        results['MSW-LASSO-lq'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso_lq, 'to': to_msw_lasso_lq})\n",
    "\n",
    "        print(f\"Window ending {stock_returns.index[start + train_window].date()}:\")\n",
    "        print(f\"CARD: TE={te_card:.4f}, TO={to_card:.4f}\")\n",
    "        print(f\"ALASSO: TE={te_alasso:.4f}, TO={to_alasso:.4f}\")\n",
    "        print(f\"SLOPE: TE={te_slope_slc:.4f}, TO={to_slope_slc:.4f}\")\n",
    "        print(f\"MSW-LASSO-SCAD: TE={te_msw_lasso_scad:.4f}, TO={to_msw_lasso_scad:.4f}\")\n",
    "        print(f\"MSW-LASSO-MCP: TE={te_msw_lasso_mcp:.4f}, TO={to_msw_lasso_mcp:.4f}\")\n",
    "        print(f\"MSW-LASSO-logM: TE={te_msw_lasso_logM:.4f}, TO={to_msw_lasso_logM:.4f}\")\n",
    "        print(f\"MSW-LASSO-lq: TE={te_msw_lasso_lq:.4f}, TO={to_msw_lasso_lq:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(X, y, train_window, test_window, kact_values, max_iter, time_limit, save_path=\"../results/s&p500\"):\n",
    "    timestamp = datetime.now().strftime('%m%d%H%M%S')\n",
    "    for kact in kact_values:\n",
    "        results = rolling_window_backtest(X, y, train_window, test_window, kact, max_iter, time_limit)\n",
    "        # 각 알고리즘별 결과를 데이터프레임으로 변환\n",
    "        dataframes = {}\n",
    "        for key, value in results.items():\n",
    "            df = pd.DataFrame(value)\n",
    "            df_name = f\"{key}_{kact}_{timestamp}\"\n",
    "            dataframes[df_name] = df\n",
    "    \n",
    "        # 데이터프레임을 CSV 파일로 저장\n",
    "        for df_name, df in dataframes.items():\n",
    "            file_path = os.path.join(save_path, f\"{df_name}.csv\")\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Saved {df_name} to {file_path}\")\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kact_values = [10, 20, 30, 40, 50] -> 5h 정도 걸림\n",
    "kact_values = [10]\n",
    "train_window = 250\n",
    "test_window =21\n",
    "# DATA usage\n",
    "X = stock_returns.drop(columns=['^GSPC'])\n",
    "y = stock_returns['^GSPC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(X, y, train_window, test_window, kact_values, max_iter=10, time_limit=60, file_path=\"../results/s&p500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('../results/s&p500_MSW-LASSO-MCP_kact_10.csv')\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('../results_s&p500_kact_20.csv')\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['te'], label=f'{key} Tracking Error')\n",
    "\n",
    "plt.title('Tracking Error Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tracking Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['to'], label=f'{key} Turnover')\n",
    "\n",
    "plt.title('Turnover Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Turnover')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMIT(Rank Meets Index tracking model)\n",
    "\n",
    "1. RMIT model makes n samples of B(weight of porfolio) -> using n Indextracking model(with diffent random seed or epoch)\n",
    "2. for n num of B it test tracking error using train set(most recent 1 month)\n",
    "3. for n num of B it test tracking error using valid set(1 month)\n",
    "4. compare rank between 2,3 and add it's loss == rank Loss + origin loss \n",
    "5. repeat 1~3 which add rank loss, stop when beta does not change(small then epsilon) \n",
    "-> for last choose best beta(smallest beta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_ranking_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pointwise ranking loss function.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.array): True objective values.\n",
    "    y_pred (np.array): Predicted objective values.\n",
    "    \n",
    "    Returns:\n",
    "    float: Pointwise ranking loss.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = np.mean((y_true - y_pred) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(y_true, y_pred, margin=1.0):\n",
    "    \"\"\"\n",
    "    Pairwise ranking loss function.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.array): True objective values.\n",
    "    y_pred (np.array): Predicted objective values.\n",
    "    margin (float): Margin for ranking.\n",
    "    \n",
    "    Returns:\n",
    "    float: Pairwise ranking loss.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = 0.0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if y_true[i] > y_true[j]:\n",
    "                loss += max(0, margin + y_pred[j] - y_pred[i])\n",
    "    return loss / (n * (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_difference_ranking_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Pairwise difference ranking loss function.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.array): True objective values.\n",
    "    y_pred (np.array): Predicted objective values.\n",
    "    \n",
    "    Returns:\n",
    "    float: Pairwise difference ranking loss.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = 0.0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            loss += (y_true[i] - y_true[j] - (y_pred[i] - y_pred[j])) ** 2\n",
    "    return loss / (n * (n - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listwise_ranking_loss(y_true, y_pred, tau=1.0):\n",
    "    \"\"\"\n",
    "    Listwise ranking loss function.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.array): True objective values.\n",
    "    y_pred (np.array): Predicted objective values.\n",
    "    tau (float): Temperature parameter.\n",
    "    \n",
    "    Returns:\n",
    "    float: Listwise ranking loss.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    def softmax(x, tau=1.0):\n",
    "        e_x = np.exp(x / tau)\n",
    "        return e_x / e_x.sum()\n",
    "\n",
    "    true_prob = softmax(-y_true, tau)\n",
    "    pred_prob = softmax(-y_pred, tau)\n",
    "    loss = -np.sum(true_prob * np.log(pred_prob))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_loss(rankloss_type, y_true, y_pred,):\n",
    "    \"\"\"\n",
    "    Return the appropriate ranking loss function based on the provided rankloss type.\n",
    "    \n",
    "    Parameters:\n",
    "    rankloss (str): Type of ranking loss ('pointwise', 'pairwise', 'listwise').\n",
    "    \n",
    "    Returns:\n",
    "    rank error rank.\n",
    "    \"\"\"\n",
    "    if rankloss_type == 'pointwise':\n",
    "        return pointwise_ranking_loss(y_true, y_pred)\n",
    "    elif rankloss_type == 'pairwise':\n",
    "        return pairwise_ranking_loss(y_true, y_pred, margin=1.0)\n",
    "    elif rankloss_type == 'pairwise-diff':\n",
    "        return pairwise_difference_ranking_loss(y_true, y_pred)\n",
    "    elif rankloss_type == 'listwise':\n",
    "        return listwise_ranking_loss(y_true, y_pred, tau=1.0)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported rankloss type. Choose from 'pointwise', 'pairwise', 'listwise'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_sampling(X, y, kact, alpha=1.0, theta=0.1, tol=1e-06, max_iter=10, time_limit=1200, add_loss=0, seed=42):\n",
    "    n, p = X.shape\n",
    "    beta_sample = []\n",
    "    weights = np.ones(p)\n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    for _ in range(max_iter):\n",
    "        m.reset()   \n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta + add_loss\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        beta_value = beta.X\n",
    "        beta_sample.append(beta_value)\n",
    "        # 결과 출력\n",
    "        if m.status == GRB.OPTIMAL or m.status == GRB.SUBOPTIMAL:\n",
    "            beta_value = beta.X\n",
    "            new_weights = np.array(new_lambda(beta_value, alpha, theta, p))\n",
    "            weights = new_weights\n",
    "            \n",
    "            if np.linalg.norm(new_weights - weights) < tol:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    m.dispose()        \n",
    "    return beta_sample\n",
    "\n",
    "\n",
    "def msw_lasso_sampling(X, y, kact, max_iter=10, tol=1e-12, penalty='MCP', a=2.5, time_limit = 1200, add_loss=0, seed=42):\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    beta_sample = []\n",
    "    def p_lambda(beta_j, lam, a):\n",
    "        #MCP: b, a =2.5\n",
    "        #SCAD: a=3.7\n",
    "        #log-M: epsilon = 1.67*10^-5\n",
    "        #lq: q=0.1\n",
    "        if penalty == 'MCP':\n",
    "            b = a \n",
    "            return lam * beta_j - (beta_j**2) / (2 * b) if beta_j <= b * lam else (b * lam**2) / 2\n",
    "        elif penalty == 'SCAD':\n",
    "            if beta_j <= lam:\n",
    "                return lam * beta_j\n",
    "            elif beta_j <= a * lam:\n",
    "                return (-beta_j**2 + 2 * a * lam * beta_j - lam**2) / (2 * (a - 1))\n",
    "            else:\n",
    "                return (a + 1) * lam**2 / 2\n",
    "        elif penalty == 'log-M':\n",
    "            eps = a\n",
    "            return lam * np.log(1+np.abs(beta_j)/eps) / np.log(1+(1/eps))\n",
    "        elif penalty == 'lq':\n",
    "            q = a \n",
    "            return lam * (abs(beta_j) **q) \n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        m.reset()   \n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta + add_loss\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        beta_value = beta.X\n",
    "        beta_sample.append(beta_value)\n",
    "        # 결과 출력\n",
    "        if m.status == GRB.OPTIMAL or m.status == GRB.SUBOPTIMAL:\n",
    "            beta_value = beta.X\n",
    "            new_weights = np.array([abs(p_lambda(beta_value[j], 1, a)) for j in range(p)])\n",
    "            weights = new_weights\n",
    "            \n",
    "            if np.linalg.norm(new_weights - weights) < tol:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    m.dispose()         \n",
    "    return beta_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_Beta(X, y, kact, algorithm_name, max_iter, time_limit, add_loss=0):\n",
    "# msw_lasso(X_train, y_train, kact=kact, penalty='lq', a=0.1, max_iter=max_iter, time_limit=time_limit)\n",
    "#beta_slope = slope(X_train, y_train, kact, max_iter=max_iter, time_limit=time_limit)\n",
    "# stock_returns, stock_index, train_window, test_window, kact, max_iter=10, time_limit=1200\n",
    "    if algorithm_name == 'SLOPE':       \n",
    "        #SLOPE\n",
    "        beta_sample = slope_sampling(X_train, y_train, kact, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-SCAD':   \n",
    "        # MSW-LASSO -SCAD\n",
    "        beta_sample = msw_lasso_sampling(X_train, y_train, kact=kact, penalty='SCAD', a=3.7, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-MCP':      \n",
    "        # MSW-LASSO -MCP\n",
    "        beta_sample = msw_lasso_sampling(X_train, y_train, kact=kact, penalty='MCP', a=2.5, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-logM':  \n",
    "        # MSW-LASSO-log-M\n",
    "        beta_sample = msw_lasso_sampling(X_train, y_train, kact=kact, penalty='log-M', a=1.67*10**(-5), max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-lq':  \n",
    "        # MSW-LASSO-lq\n",
    "        beta_sample = msw_lasso_sampling(X_train, y_train, kact=kact, penalty='lq', a=0.1, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    \n",
    "    return beta_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Beta(X, y, kact, algorithm_name, max_iter, time_limit, add_loss=0):\n",
    "# msw_lasso(X_train, y_train, kact=kact, penalty='lq', a=0.1, max_iter=max_iter, time_limit=time_limit)\n",
    "#beta_slope = slope(X_train, y_train, kact, max_iter=max_iter, time_limit=time_limit)\n",
    "# stock_returns, stock_index, train_window, test_window, kact, max_iter=10, time_limit=1200\n",
    "    if algorithm_name == 'SLOPE':       \n",
    "        #SLOPE\n",
    "        beta_sample = slope(X_train, y_train, kact, max_iter=max_iter, time_limit=time_limit)\n",
    "    elif algorithm_name == 'MSW-LASSO-SCAD':   \n",
    "        # MSW-LASSO -SCAD\n",
    "        beta_sample = msw_lasso(X_train, y_train, kact=kact, penalty='SCAD', a=3.7, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-MCP':      \n",
    "        # MSW-LASSO -MCP\n",
    "        beta_sample = msw_lasso(X_train, y_train, kact=kact, penalty='MCP', a=2.5, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-logM':  \n",
    "        # MSW-LASSO-log-M\n",
    "        beta_sample = msw_lasso(X_train, y_train, kact=kact, penalty='log-M', a=1.67*10**(-5), max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    elif algorithm_name == 'MSW-LASSO-lq':  \n",
    "        # MSW-LASSO-lq\n",
    "        beta_sample = msw_lasso(X_train, y_train, kact=kact, penalty='lq', a=0.1, max_iter=max_iter, time_limit=time_limit, add_loss=add_loss)\n",
    "    \n",
    "    return beta_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMIT(X, y, test_window_size=21, kact=10, algorithm='SLOPE', rank_type='pointwise', n_models=10, max_iter=10, time_limit=60):\n",
    "    beta = None\n",
    "    train_errors = []\n",
    "    valid_errors = []\n",
    "    rank_loss_value = 0 \n",
    "    X_train = X[:-2*test_window_size]\n",
    "    y_train = y[:-2*test_window_size]\n",
    "    X_train_last = X[-2*test_window_size:-test_window_size]\n",
    "    y_train_last = y[-2*test_window_size:-test_window_size]\n",
    "    X_val = X[-test_window_size:]\n",
    "    y_val = y[-test_window_size:]\n",
    "    \n",
    "    for _ in range(max_iter-1): \n",
    "        # 1. Generate n samples of B using n regression models & use updated rank_loss \n",
    "        B_samples = sampling_Beta(X_train, y_train, kact, algorithm_name=algorithm, max_iter=n_models, time_limit=time_limit, add_loss = rank_loss_value)\n",
    "        # 2. Test tracking error using train set(1month)\n",
    "        for B in B_samples:\n",
    "            te, to = evaluate_portfolio(X_train_last, y_train_last, B)\n",
    "            train_errors.append(te)\n",
    "        # 3. Test tracking error using valid set\n",
    "        valid_errors = []\n",
    "        for B in B_samples:\n",
    "            te, to = evaluate_portfolio(X_val, y_val, B)\n",
    "            valid_errors.append(te)\n",
    "        # 4. Compare rank between train and valid errors and add its loss\n",
    "        rank_loss_value = rank_loss(rank_type, train_errors, valid_errors)\n",
    "\n",
    "    #5. compute last beta using rankloss + origin loss of algorithm \n",
    "    # use all data + val\n",
    "    beta = calculate_Beta(X, y, kact, algorithm_name=algorithm, max_iter=max_iter, time_limit=time_limit, add_loss = rank_loss_value)\n",
    "\n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_stocks = stock_returns.drop(columns=['^GSPC'])\n",
    "stock_index = stock_returns['^GSPC']\n",
    "\n",
    "train_data = stock_stocks.iloc[:250]\n",
    "\n",
    "# Filter out columns with NaN values in the current window\n",
    "valid_assets_train = train_data.dropna(axis=1)\n",
    "valid_assets = valid_assets_train.columns.intersection(valid_assets_train.columns)\n",
    "\n",
    "X_train = valid_assets_train[valid_assets].values\n",
    "y_train = stock_index.iloc[:250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x3808f38d\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.29s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3433    1.0000035e+00   4.862231e+00   0.000000e+00      5s\n",
      "    8760    1.0000001e+00   0.000000e+00   0.000000e+00      7s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 7.04 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    7s\n",
      "H    0     0                       1.0000167    1.00000  0.00%     -    8s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 8.99 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016680157e+00, best bound 1.000000099790e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.18s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    4361    9.9967177e-01   4.995545e-02   0.000000e+00      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      6s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 5.96 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    6s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    7s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 7.87 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.15s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    5939    1.0000015e+00   0.000000e+00   1.343468e-03      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      6s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 5.51 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    6s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    7s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 7.24 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.19s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    5939    1.0000015e+00   0.000000e+00   1.343468e-03      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      6s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 5.62 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    6s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    7s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 7.82 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.18s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3627    9.9993700e-01   1.580896e-01   0.000000e+00      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      7s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 6.83 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    7s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    8s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 8.71 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.20s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3330    1.0000036e+00   3.467845e+00   0.000000e+00      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      9s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 8.60 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    8s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -   10s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 10.60 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.69s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    1739    1.0000005e+00   7.203906e-01   0.000000e+00      5s\n",
      "    4580    9.9967376e-01   2.474090e-02   0.000000e+00     10s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00     14s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 12.67 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -   13s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -   15s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 15.30 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.32s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3222    1.0000037e+00   4.089126e-01   0.000000e+00      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 7.85 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    8s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    9s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 9.86 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x59994981\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001487\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.31s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3627    9.9993700e-01   1.580896e-01   0.000000e+00      5s\n",
      "    8760    1.0000002e+00   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 7.34 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    8s\n",
      "H    0     0                       1.0000168    1.00000  0.00%     -    9s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 9.75 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016769570e+00, best bound 1.000000189202e+00, gap 0.0017%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 638 rows, 1272 columns and 2544 nonzeros\n",
      "Model fingerprint: 0x3808f38d\n",
      "Model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 1e+01]\n",
      "  QObjective range [5e-09, 2e+08]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0001486\n",
      "Warning: diagonal adjustment of 2.2e-08 performed to make Q PSD\n",
      "Presolve time: 0.18s\n",
      "Presolved: 638 rows, 1272 columns, 2544 nonzeros\n",
      "Presolved model has 201894 quadratic objective terms\n",
      "Variable types: 636 continuous, 636 integer (636 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3739    9.9993730e-01   1.254121e-01   0.000000e+00      5s\n",
      "    8760    1.0000001e+00   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 8760 iterations, 7.82 seconds (3.96 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   90    1.00015    1.00000  0.01%     -    8s\n",
      "H    0     0                       1.0000167    1.00000  0.00%     -    9s\n",
      "\n",
      "Explored 1 nodes (8760 simplex iterations) in 9.54 seconds (4.56 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.00002 1.00015 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000016680157e+00, best bound 1.000000099790e+00, gap 0.0017%\n"
     ]
    }
   ],
   "source": [
    "## RMIT\n",
    "beta_RMIT = RMIT(X_train, y_train, test_window_size=21, kact=10,  algorithm='SLOPE', rank_type='pointwise', n_models=10, max_iter=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_card > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
