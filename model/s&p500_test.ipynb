{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stock data.\n",
    "file_path = '..\\data\\s&p500\\clean_s&p500_stock_data.csv'\n",
    "stock_data = pd.read_csv(file_path, index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>1268.800049</td>\n",
       "      <td>23.962805</td>\n",
       "      <td>37.450001</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.976089</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>58.470001</td>\n",
       "      <td>27.014999</td>\n",
       "      <td>39.288540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.804457</td>\n",
       "      <td>66.485435</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>76.480003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>1273.459961</td>\n",
       "      <td>24.027182</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>43.830002</td>\n",
       "      <td>2.677500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.004877</td>\n",
       "      <td>6.151111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.660000</td>\n",
       "      <td>58.570000</td>\n",
       "      <td>27.264999</td>\n",
       "      <td>39.235836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.948238</td>\n",
       "      <td>67.116508</td>\n",
       "      <td>42.410000</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>1273.479980</td>\n",
       "      <td>24.656652</td>\n",
       "      <td>39.709999</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>2.656429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.249577</td>\n",
       "      <td>6.061111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>58.279999</td>\n",
       "      <td>26.955000</td>\n",
       "      <td>38.814228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.670740</td>\n",
       "      <td>66.407768</td>\n",
       "      <td>42.529999</td>\n",
       "      <td>77.720001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>1285.449951</td>\n",
       "      <td>24.785408</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>2.725000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.619022</td>\n",
       "      <td>6.173333</td>\n",
       "      <td>...</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>59.430000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>38.577076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.620417</td>\n",
       "      <td>66.067963</td>\n",
       "      <td>44.119999</td>\n",
       "      <td>78.529999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>1290.150024</td>\n",
       "      <td>24.713877</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>44.560001</td>\n",
       "      <td>2.716071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.348318</td>\n",
       "      <td>6.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>27.645000</td>\n",
       "      <td>39.104084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.757010</td>\n",
       "      <td>68.407768</td>\n",
       "      <td>44.790001</td>\n",
       "      <td>77.879997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC          A        AAL        AAP      AAPL  ABBV  \\\n",
       "date                                                                       \n",
       "2006-01-03  1268.800049  23.962805  37.450001  43.520000  2.669643   NaN   \n",
       "2006-01-04  1273.459961  24.027182  39.200001  43.830002  2.677500   NaN   \n",
       "2006-01-05  1273.479980  24.656652  39.709999  44.040001  2.656429   NaN   \n",
       "2006-01-06  1285.449951  24.785408  39.000000  43.990002  2.725000   NaN   \n",
       "2006-01-09  1290.150024  24.713877  38.610001  44.560001  2.716071   NaN   \n",
       "\n",
       "             ABMD  ABS        ABT      ACGL  ...        XEL        XOM  \\\n",
       "date                                         ...                         \n",
       "2006-01-03   9.44  NaN  18.976089  6.120000  ...  18.570000  58.470001   \n",
       "2006-01-04   9.62  NaN  19.004877  6.151111  ...  18.660000  58.570000   \n",
       "2006-01-05   9.55  NaN  19.249577  6.061111  ...  18.650000  58.279999   \n",
       "2006-01-06   9.75  NaN  19.619022  6.173333  ...  18.719999  59.430000   \n",
       "2006-01-09  10.15  NaN  20.348318  6.116667  ...  18.670000  59.400002   \n",
       "\n",
       "                 XRAY        XRX  XYL        YUM        ZBH       ZBRA  \\\n",
       "date                                                                     \n",
       "2006-01-03  27.014999  39.288540  NaN  16.804457  66.485435  42.830002   \n",
       "2006-01-04  27.264999  39.235836  NaN  16.948238  67.116508  42.410000   \n",
       "2006-01-05  26.955000  38.814228  NaN  17.670740  66.407768  42.529999   \n",
       "2006-01-06  27.375000  38.577076  NaN  17.620417  66.067963  44.119999   \n",
       "2006-01-09  27.645000  39.104084  NaN  17.757010  68.407768  44.790001   \n",
       "\n",
       "                 ZION  ZTS  \n",
       "date                        \n",
       "2006-01-03  76.480003  NaN  \n",
       "2006-01-04  77.019997  NaN  \n",
       "2006-01-05  77.720001  NaN  \n",
       "2006-01-06  78.529999  NaN  \n",
       "2006-01-09  77.879997  NaN  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>3844.820068</td>\n",
       "      <td>149.229996</td>\n",
       "      <td>12.71</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>131.860001</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>63.380001</td>\n",
       "      <td>...</td>\n",
       "      <td>70.930000</td>\n",
       "      <td>108.680000</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>14.61</td>\n",
       "      <td>109.730003</td>\n",
       "      <td>128.899994</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>248.220001</td>\n",
       "      <td>48.450001</td>\n",
       "      <td>145.759995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>3829.250000</td>\n",
       "      <td>149.550003</td>\n",
       "      <td>12.53</td>\n",
       "      <td>145.020004</td>\n",
       "      <td>130.029999</td>\n",
       "      <td>162.990005</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.570000</td>\n",
       "      <td>63.619999</td>\n",
       "      <td>...</td>\n",
       "      <td>71.570000</td>\n",
       "      <td>110.190002</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>14.70</td>\n",
       "      <td>110.720001</td>\n",
       "      <td>129.899994</td>\n",
       "      <td>127.279999</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>48.840000</td>\n",
       "      <td>145.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>3783.219971</td>\n",
       "      <td>148.089996</td>\n",
       "      <td>12.32</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>162.229996</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.830002</td>\n",
       "      <td>62.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>70.570000</td>\n",
       "      <td>108.379997</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>14.37</td>\n",
       "      <td>108.940002</td>\n",
       "      <td>129.309998</td>\n",
       "      <td>125.989998</td>\n",
       "      <td>246.839996</td>\n",
       "      <td>47.970001</td>\n",
       "      <td>143.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>3849.280029</td>\n",
       "      <td>151.089996</td>\n",
       "      <td>12.70</td>\n",
       "      <td>146.309998</td>\n",
       "      <td>129.610001</td>\n",
       "      <td>162.559998</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.309998</td>\n",
       "      <td>63.110001</td>\n",
       "      <td>...</td>\n",
       "      <td>71.070000</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>32.279999</td>\n",
       "      <td>14.49</td>\n",
       "      <td>111.639999</td>\n",
       "      <td>129.990005</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>257.529999</td>\n",
       "      <td>49.080002</td>\n",
       "      <td>148.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>3839.500000</td>\n",
       "      <td>149.649994</td>\n",
       "      <td>12.72</td>\n",
       "      <td>147.029999</td>\n",
       "      <td>129.929993</td>\n",
       "      <td>161.610001</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.790001</td>\n",
       "      <td>62.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>70.110001</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>14.60</td>\n",
       "      <td>110.570000</td>\n",
       "      <td>128.080002</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>256.410004</td>\n",
       "      <td>49.160000</td>\n",
       "      <td>146.550003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC           A    AAL         AAP        AAPL  \\\n",
       "date                                                                 \n",
       "2022-12-23  3844.820068  149.229996  12.71  143.279999  131.860001   \n",
       "2022-12-27  3829.250000  149.550003  12.53  145.020004  130.029999   \n",
       "2022-12-28  3783.219971  148.089996  12.32  145.300003  126.040001   \n",
       "2022-12-29  3849.280029  151.089996  12.70  146.309998  129.610001   \n",
       "2022-12-30  3839.500000  149.649994  12.72  147.029999  129.929993   \n",
       "\n",
       "                  ABBV        ABMD  ABS         ABT       ACGL  ...  \\\n",
       "date                                                            ...   \n",
       "2022-12-23  163.100006  381.019989  NaN  108.180000  63.380001  ...   \n",
       "2022-12-27  162.990005  381.019989  NaN  108.570000  63.619999  ...   \n",
       "2022-12-28  162.229996  381.019989  NaN  107.830002  62.599998  ...   \n",
       "2022-12-29  162.559998  381.019989  NaN  110.309998  63.110001  ...   \n",
       "2022-12-30  161.610001  381.019989  NaN  109.790001  62.779999  ...   \n",
       "\n",
       "                  XEL         XOM       XRAY    XRX         XYL         YUM  \\\n",
       "date                                                                          \n",
       "2022-12-23  70.930000  108.680000  31.830000  14.61  109.730003  128.899994   \n",
       "2022-12-27  71.570000  110.190002  32.070000  14.70  110.720001  129.899994   \n",
       "2022-12-28  70.570000  108.379997  30.980000  14.37  108.940002  129.309998   \n",
       "2022-12-29  71.070000  109.199997  32.279999  14.49  111.639999  129.990005   \n",
       "2022-12-30  70.110001  110.300003  31.840000  14.60  110.570000  128.080002   \n",
       "\n",
       "                   ZBH        ZBRA       ZION         ZTS  \n",
       "date                                                       \n",
       "2022-12-23  126.690002  248.220001  48.450001  145.759995  \n",
       "2022-12-27  127.279999  251.000000  48.840000  145.300003  \n",
       "2022-12-28  125.989998  246.839996  47.970001  143.830002  \n",
       "2022-12-29  127.830002  257.529999  49.080002  148.149994  \n",
       "2022-12-30  127.500000  256.410004  49.160000  146.550003  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.014162</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.016760</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>-0.030685</td>\n",
       "      <td>-0.004663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006816</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.004542</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.007566</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.023139</td>\n",
       "      <td>0.030035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.002541</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.005844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013508</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-0.013631</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>-0.014693</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.004349</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>-0.010800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ^GSPC         A       AAL       AAP      AAPL      ABBV  ABMD  \\\n",
       "date                                                                           \n",
       "2022-12-23  0.005868  0.001476  0.011943  0.008446 -0.002798 -0.001041   0.0   \n",
       "2022-12-27 -0.004050  0.002144 -0.014162  0.012144 -0.013878 -0.000674   0.0   \n",
       "2022-12-28 -0.012021 -0.009763 -0.016760  0.001931 -0.030685 -0.004663   0.0   \n",
       "2022-12-29  0.017461  0.020258  0.030844  0.006951  0.028324  0.002034   0.0   \n",
       "2022-12-30 -0.002541 -0.009531  0.001575  0.004921  0.002469 -0.005844   0.0   \n",
       "\n",
       "            ABS       ABT      ACGL  ...       XEL       XOM      XRAY  \\\n",
       "date                                 ...                                 \n",
       "2022-12-23  0.0  0.001389  0.008433  ...  0.012852  0.026445  0.011118   \n",
       "2022-12-27  0.0  0.003605  0.003787  ...  0.009023  0.013894  0.007540   \n",
       "2022-12-28  0.0 -0.006816 -0.016033  ... -0.013972 -0.016426 -0.033988   \n",
       "2022-12-29  0.0  0.022999  0.008147  ...  0.007085  0.007566  0.041963   \n",
       "2022-12-30  0.0 -0.004714 -0.005229  ... -0.013508  0.010073 -0.013631   \n",
       "\n",
       "                 XRX       XYL       YUM       ZBH      ZBRA      ZION  \\\n",
       "date                                                                     \n",
       "2022-12-23 -0.003411 -0.000728  0.000621 -0.000789  0.002869  0.003521   \n",
       "2022-12-27  0.006160  0.009022  0.007758  0.004657  0.011200  0.008050   \n",
       "2022-12-28 -0.022449 -0.016077 -0.004542 -0.010135 -0.016574 -0.017813   \n",
       "2022-12-29  0.008351  0.024784  0.005259  0.014604  0.043307  0.023139   \n",
       "2022-12-30  0.007591 -0.009584 -0.014693 -0.002582 -0.004349  0.001630   \n",
       "\n",
       "                 ZTS  \n",
       "date                  \n",
       "2022-12-23  0.005033  \n",
       "2022-12-27 -0.003156  \n",
       "2022-12-28 -0.010117  \n",
       "2022-12-29  0.030035  \n",
       "2022-12-30 -0.010800  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate daily returns\n",
    "stock_returns = stock_data.pct_change().dropna(how='all')\n",
    "stock_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_returns['^GSPC'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment setup\n",
    "- daily return을 기준으로 index tracking 설정\n",
    "- 월별 리벨런싱 가정\n",
    "- 2006/01/01 ~ 2022-12/30\n",
    "- k act: 10% 20% 30% 40% 50% - 전체 주식의 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def card(X, y, kact, time_limit=1200, seed=42):\n",
    "#     #n number of row, day\n",
    "#     n, p = X.shape\n",
    "#     m = gp.Model()\n",
    "#     m.setParam('TimeLimit', time_limit)\n",
    "#     m.setParam(GRB.Param.Seed, seed)\n",
    "#     beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "#     z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    \n",
    "#     objective = (1/n) * ((y - X @ beta) @ (y - X @ beta))\n",
    "#     #objective 설정\n",
    "#     m.setObjective(objective, GRB.MINIMIZE)\n",
    "#     #constraint 0: z의 설정 beta가 0이 아니면 1로 설정\n",
    "#     m.addConstr(beta <= z, name=\"c0\")\n",
    "#     #constraint 1: full investment\n",
    "#     m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "#     #constraine 2: cardinality constraint\n",
    "#     m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "#     m.optimize()\n",
    "    \n",
    "#     return beta.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(X, y, kact, time_limit=1200):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) <= kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_stocks = stock_returns.drop(columns=['^GSPC'])\n",
    "stock_index = stock_returns['^GSPC']\n",
    "\n",
    "train_data = stock_stocks.iloc[:250]\n",
    "\n",
    "# Filter out columns with NaN values in the current window\n",
    "valid_assets_train = train_data.dropna(axis=1)\n",
    "valid_assets = valid_assets_train.columns.intersection(valid_assets_train.columns)\n",
    "\n",
    "X_train = valid_assets_train[valid_assets].values\n",
    "y_train = stock_index.iloc[:250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-07-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\cvxpy\\problems\\problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # CARD\n",
    "beta_card = card(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_card > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALASSO Algorithm\n",
    "- make initial beta using OLS\n",
    "- can not find propal lambda in the context\n",
    "- FIX!: ALASSO solution is always converge to 1,0,0,0 -> shrinking is too strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def alasso(X, y, kact, time_limit=1200, lambdas=1):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Initial Lasso to get initial weights\n",
    "    lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "    lasso.fit(X, y)\n",
    "    beta_init = lasso.coef_\n",
    "    \n",
    "    # Adaptive weights\n",
    "    weights = 1 / (np.abs(beta_init) + 1e-6)\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + lambdas * cp.sum(weights @ cp.abs(beta)))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) == kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALASSO\n",
    "beta_alasso = alasso(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_alasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted LASSO- SLOPE\n",
    "detail is from Sparse index clones via the sorted l1-Norm\n",
    "SLOPE—ADAPTIVE VARIABLE SELECTION VIA CONVEX OPTIMIZATION\n",
    "\n",
    "- initial guess beta를 가지고 추정 시작\n",
    "- 이후 update\n",
    "- lambda of model: aplha(=sigma of model)(1-i*theta)~ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(X, y, kact, alpha=1.0, theta=0.1, time_limit=1200):\n",
    "    \"\"\"\n",
    "    Solve the SLOPE optimization problem using Gurobi with an activation constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like, shape (T, K)\n",
    "        The return matrix of benchmark constituents.\n",
    "    y : array-like, shape (T,)\n",
    "        The benchmark returns.\n",
    "    kact : int\n",
    "        Number of active variables (non-zero coefficients) allowed.\n",
    "    alpha : float, optional\n",
    "        Regularization parameter for the lambda sequence.\n",
    "    theta : float, optional\n",
    "        Decay rate for the lambda sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples and features\n",
    "    n, p = X.shape\n",
    "    \n",
    "    # Generate the lambda sequence\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * p))) for i in range(1, p + 1)])\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    sorted_abs_beta = cp.Variable(p, nonneg=True)\n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + cp.sum(cp.multiply(lambdas, sorted_abs_beta)))\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) <= kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z,  # Link binary variables with beta\n",
    "    ]\n",
    "\n",
    "    #abs for DCP rules but beta is >=0 so we don't need absolute constraints\n",
    "    constraints += [sorted_abs_beta == beta]\n",
    "    # Sorting constraints\n",
    "    for i in range(p-1):\n",
    "        constraints.append(sorted_abs_beta[i] >= sorted_abs_beta[i+1])\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Strict inequalities are not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SLOPE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_slope \u001b[38;5;241m=\u001b[39m \u001b[43mslope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 42\u001b[0m, in \u001b[0;36mslope\u001b[1;34m(X, y, kact, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     41\u001b[0m     constraints\u001b[38;5;241m.\u001b[39mappend(sorted_beta[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m sorted_beta[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 42\u001b[0m constraints\u001b[38;5;241m.\u001b[39mappend(sorted_beta \u001b[38;5;241m==\u001b[39m cp\u001b[38;5;241m.\u001b[39mhstack(\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Problem definition\u001b[39;00m\n\u001b[0;32m     45\u001b[0m prob \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(objective, constraints)\n",
      "File \u001b[1;32mc:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\cvxpy\\expressions\\expression.py:762\u001b[0m, in \u001b[0;36mExpression.__lt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__lt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: ExpressionLike):\n\u001b[1;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrict inequalities are not allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Strict inequalities are not allowed."
     ]
    }
   ],
   "source": [
    "# SLOPE\n",
    "beta_slope = slope(X_train, y_train, kact=10, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_slope > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOPE-SLC\n",
    "1. Sorted LASSO의 변형 형태\n",
    "2. compute for each group the median partial correlation of consituents and keep only groups which are including 75th percent quantile for the equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_optimization_initial(X, y, alpha=1.0, theta=0.5, time_limit=1200): \n",
    "    n, p = X.shape\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * p))) for i in range(1, p + 1)])\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    sorted_abs_beta = cp.Variable(p)\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + lambdas @ sorted_abs_beta)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "    ]\n",
    "    \n",
    "    # Absolute value constraints\n",
    "    constraints += [sorted_abs_beta >= beta, sorted_abs_beta >= -beta]\n",
    "    # Sorting constraints\n",
    "    constraints += [sorted_abs_beta[i] >= sorted_abs_beta[i+1] for i in range(p-1)]\n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_partial_correlation(X, y):\n",
    "    # Use LassoLarsIC to find significant features\n",
    "    model = LassoLarsIC(criterion='bic')\n",
    "    model.fit(X, y)\n",
    "    active_features = np.where(model.coef_ != 0)[0]\n",
    "    \n",
    "    partial_corr = np.zeros(X.shape[1])\n",
    "    for i in active_features:\n",
    "        residual_y = y - model.predict(X[:, active_features])\n",
    "        residual_x = X[:, i] - model.predict(X[:, active_features])\n",
    "        partial_corr[i] = np.corrcoef(residual_y, residual_x)[0, 1]\n",
    "    \n",
    "    return partial_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_slc_optimization(X, y, kact, alpha=1.0, theta=0.5, time_limit=1200):\n",
    "    \n",
    "    # Step 1: Solve SLOPE\n",
    "    beta_initial = slope_optimization_initial(X, y, alpha, theta, time_limit)\n",
    "    \n",
    "    # Step 2: Compute partial correlation for each asset\n",
    "    partial_corr = compute_partial_correlation(X, y)\n",
    "    \n",
    "    # Step 3: Select groups based on median partial correlation\n",
    "    median_corr = np.median(partial_corr)\n",
    "    threshold = np.percentile(partial_corr, 75)\n",
    "    active_indices = np.where(partial_corr >= threshold)[0]\n",
    "    \n",
    "    # Step 4: Rescale SLOPE estimates to sum to 1\n",
    "    beta_rescaled = np.zeros_like(beta_initial)\n",
    "    beta_rescaled[active_indices] = beta_initial[active_indices]\n",
    "    beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "    # Step 5: Ensure the number of active weights is less than or equal to kact\n",
    "    if np.sum(beta_rescaled > 0) > kact:\n",
    "        sorted_indices = np.argsort(beta_rescaled)[::-1]\n",
    "        beta_rescaled[sorted_indices[kact:]] = 0\n",
    "        beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "    return beta_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cvxpy' has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SLOPE-SLC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_slope_slc \u001b[38;5;241m=\u001b[39m \u001b[43mslope_slc_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m, in \u001b[0;36mslope_slc_optimization\u001b[1;34m(X, y, kact, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslope_slc_optimization\u001b[39m(X, y, kact, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1200\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Step 1: Solve SLOPE\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     beta_initial \u001b[38;5;241m=\u001b[39m \u001b[43mslope_optimization_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: Compute partial correlation for each asset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     partial_corr \u001b[38;5;241m=\u001b[39m compute_partial_correlation(X, y)\n",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m, in \u001b[0;36mslope_optimization_initial\u001b[1;34m(X, y, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Sorting constraints\u001b[39;00m\n\u001b[0;32m     23\u001b[0m constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [sorted_abs_beta[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m sorted_abs_beta[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m---> 24\u001b[0m constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [sorted_abs_beta \u001b[38;5;241m==\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m(abs_beta, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Problem definition\u001b[39;00m\n\u001b[0;32m     27\u001b[0m prob \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(objective, constraints)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cvxpy' has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "# SLOPE-SLC\n",
    "beta_slope_slc = slope_slc_optimization(X_train, y_train, kact=10, time_limit=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_negative_count = np.sum(beta_slope_slc > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSW_LASSO\n",
    "detail is from High-dimensional Sprase index tracking based on a multi-step coonvex optimization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msw_lasso(X, y, kact, max_iter=100, tol=1e-4, penalty='MCP', a=2.5, time_limit = 1200, seed=42):\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    \n",
    "    def p_lambda(beta_j, lam, a):\n",
    "        #MCP: b, a =2.5\n",
    "        #SCAD: a=3.7\n",
    "        #log-M: epsilon = 1.67*10^-5\n",
    "        #lq: q=0.1\n",
    "        if penalty == 'MCP':\n",
    "            b = a \n",
    "            return lam * beta_j - (beta_j**2) / (2 * b) if beta_j <= b * lam else (b * lam**2) / 2\n",
    "        elif penalty == 'SCAD':\n",
    "            if beta_j <= lam:\n",
    "                return lam * beta_j\n",
    "            elif beta_j <= a * lam:\n",
    "                return (-beta_j**2 + 2 * a * lam * beta_j - lam**2) / (2 * (a - 1))\n",
    "            else:\n",
    "                return (a + 1) * lam**2 / 2\n",
    "        elif penalty == 'log-M':\n",
    "            eps = a\n",
    "            return lam * np.log(1+np.abs(beta_j)/eps) / np.log(1+(1/eps))\n",
    "        elif penalty == 'lq':\n",
    "            q = a \n",
    "            return lam * (abs(beta_j) **q) \n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        m = gp.Model()\n",
    "        m.setParam('TimeLimit', time_limit)\n",
    "        m.setParam(GRB.Param.Seed, seed)\n",
    "        beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "        z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.addConstr(beta <= z, name=\"c0\")\n",
    "        m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "        m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "        m.optimize()\n",
    "        \n",
    "        beta_value = beta.X\n",
    "        new_weights = np.array([abs(p_lambda(beta_value[j], 1, a)) for j in range(p)])\n",
    "        \n",
    "        if np.linalg.norm(new_weights - weights) < tol:\n",
    "            break\n",
    "        weights = new_weights\n",
    "    \n",
    "    return beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-07-25\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x301ba4af\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0007714\n",
      "Presolve time: 0.07s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 6330 iterations, 2.20 seconds (2.20 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.0001054    1.00000  0.01%     -    2s\n",
      "H    0     0                       1.0000151    1.00000  0.00%     -    2s\n",
      "     0     0    1.00000    0  103    1.00002    1.00000  0.00%     -    2s\n",
      "\n",
      "Explored 1 nodes (6330 simplex iterations) in 2.46 seconds (2.21 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.00002 1.00011 1.00077 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000015133005e+00, best bound 1.000000110964e+00, gap 0.0015%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x8e497165\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 3e-01]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 0.0007714\n",
      "Presolve time: 0.11s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 8.826420e-08, 4963 iterations, 0.75 seconds (1.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.0001054    0.00000   100%     -    1s\n",
      "     0     0    0.00000    0  115    0.00011    0.00000   100%     -    1s\n",
      "H    0     0                       0.0000182    0.00000   100%     -    1s\n",
      "     0     0    0.00000    0  115    0.00002    0.00000   100%     -    2s\n",
      "H    0     0                       0.0000053    0.00000  98.3%     -    3s\n",
      "H    0     0                       0.0000043    0.00000  97.9%     -    4s\n",
      "     0     2    0.00000    0  115    0.00000    0.00000  97.9%     -    4s\n",
      "     1     4    0.00000    1  114    0.00000    0.00000  97.9%  1291    5s\n",
      "H   27    32                       0.0000040    0.00000  97.8%   551   10s\n",
      "H   29    32                       0.0000039    0.00000  97.8%   546   10s\n",
      "H   30    32                       0.0000037    0.00000  97.6%   533   10s\n",
      "H   61    66                       0.0000033    0.00000  97.4%   411   16s\n",
      "H   63    66                       0.0000033    0.00000  97.3%   401   16s\n",
      "    99   104    0.00000   28  127    0.00000    0.00000  97.3%   330   20s\n",
      "H  100   104                       0.0000033    0.00000  97.3%   327   20s\n",
      "H  142   162                       0.0000032    0.00000  97.2%   272   21s\n",
      "H  268   294                       0.0000031    0.00000  97.2%   195   24s\n",
      "   293   326    0.00000   81  128    0.00000    0.00000  97.2%   186   25s\n",
      "H  527   540                       0.0000031    0.00000  97.2%   133   27s\n",
      "H  539   581                       0.0000031    0.00000  97.2%   131   27s\n",
      "   786   796    0.00000    6  112    0.00000    0.00000  97.2%   104   30s\n",
      "H 1006   898                       0.0000030    0.00000  97.1%   100   34s\n",
      "  1011   915    0.00000   24  110    0.00000    0.00000  97.1%   101   35s\n",
      "  1116   999    0.00000   20  114    0.00000    0.00000  96.9%   110   40s\n",
      "  1133  1020    0.00000   17  109    0.00000    0.00000  96.9%   118   45s\n",
      "H 1134   968                       0.0000030    0.00000  96.9%   118   45s\n",
      "H 1139   920                       0.0000029    0.00000  96.8%   123   45s\n",
      "H 1190   909                       0.0000029    0.00000  96.8%   128   49s\n",
      "  1192   920    0.00000   20  115    0.00000    0.00000  96.8%   128   50s\n",
      "H 1213   883                       0.0000029    0.00000  96.7%   129   51s\n",
      "  1296   942    0.00000   27  112    0.00000    0.00000  96.7%   130   55s\n",
      "H 1373   973                       0.0000029    0.00000  96.7%   129   59s\n",
      "H 1396   926                       0.0000026    0.00000  96.4%   128   59s\n",
      "  1440   958    0.00000   35  122    0.00000    0.00000  96.4%   127   60s\n",
      "\n",
      "Explored 1448 nodes (188172 simplex iterations) in 60.06 seconds (52.63 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 2.64236e-06 2.86802e-06 2.90432e-06 ... 3.19978e-06\n",
      "\n",
      "Time limit reached\n",
      "Best objective 2.642355213373e-06, best bound 9.476878551207e-08, gap 96.4135%\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x615d49b4\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 2e-01]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 0.0007714\n",
      "Presolve time: 0.09s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.260894e-07, 4268 iterations, 0.75 seconds (0.85 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.0001054    0.00000   100%     -    1s\n",
      "     0     0    0.00000    0  107    0.00011    0.00000   100%     -    1s\n",
      "H    0     0                       0.0000136    0.00000  99.1%     -    1s\n",
      "     0     0    0.00000    0  107    0.00001    0.00000  99.1%     -    2s\n",
      "H    0     0                       0.0000054    0.00000  97.7%     -    3s\n",
      "H    0     0                       0.0000038    0.00000  96.7%     -    4s\n",
      "     0     2    0.00000    0  107    0.00000    0.00000  96.7%     -    5s\n",
      "    59    64    0.00000   15  122    0.00000    0.00000  96.7%   339   11s\n",
      "H   61    64                       0.0000037    0.00000  96.6%   332   11s\n",
      "   196   220    0.00000   58  131    0.00000    0.00000  96.6%   195   15s\n",
      "   526   572    0.00000  143  118    0.00000    0.00000  96.6%   119   20s\n",
      "H 1003   948                       0.0000037    0.00000  96.6%  83.0   26s\n",
      "H 1059   970                       0.0000037    0.00000  96.6%  87.0   27s\n",
      "  1117  1023    0.00000   20  107    0.00000    0.00000  96.6%  92.2   30s\n",
      "  1122  1029    0.00000   14  102    0.00000    0.00000  96.6%   100   36s\n",
      "  1128  1039    0.00000   16  109    0.00000    0.00000  96.6%   108   42s\n",
      "H 1144   998                       0.0000036    0.00000  96.5%   117   49s\n",
      "  1152  1003    0.00000   18  106    0.00000    0.00000  96.5%   134   50s\n",
      "H 1158   952                       0.0000035    0.00000  96.4%   134   50s\n",
      "  1168   967    0.00000   19  117    0.00000    0.00000  96.4%   144   55s\n",
      "  1187   981    0.00000   20  125    0.00000    0.00000  96.4%   164   60s\n",
      "\n",
      "Explored 1198 nodes (199892 simplex iterations) in 60.05 seconds (59.92 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 3.52867e-06 3.55407e-06 3.71015e-06 ... 0.000771402\n",
      "\n",
      "Time limit reached\n",
      "Best objective 3.528666918271e-06, best bound 1.260894335144e-07, gap 96.4267%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # msw_lasso\n",
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest\n",
    "## Experiment result \n",
    "- Turn over 비용\n",
    "- Tracking error(for out of sample)\n",
    "- Computing time(running time second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(X, y, beta):\n",
    "    tracking_error = np.sqrt(np.mean((y - X @ beta)**2))\n",
    "    turnover = np.sum(np.abs(beta[1:] - beta[:-1])) / len(beta)\n",
    "    return tracking_error, turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_backtest(stock_returns, stock_index, train_window, test_window, kact, lambdas):\n",
    "    results = {'CARD': [], 'ALASSO': [], 'SLOPE-SLC': [], 'MSW-LASSO': []}\n",
    "    n = len(stock_returns)\n",
    "    \n",
    "    for start in range(0, n - train_window - test_window + 1, test_window):\n",
    "        train_data = stock_returns.iloc[start:start + train_window]\n",
    "        test_data = stock_returns.iloc[start + train_window:start + train_window + test_window]\n",
    "    \n",
    "        # Filter out columns with NaN values in the current window\n",
    "        valid_assets_train = train_data.dropna(axis=1)\n",
    "        valid_assets_test = test_data.dropna(axis=1)\n",
    "        valid_assets = valid_assets_train.columns.intersection(valid_assets_test.columns)\n",
    "        \n",
    "        X_train = valid_assets_train[valid_assets].values\n",
    "        y_train = stock_index.iloc[start:start + train_window].values\n",
    "        \n",
    "        X_test = valid_assets_test[valid_assets].values\n",
    "        y_test = stock_index.iloc[start + train_window:start + train_window + test_window].values\n",
    "        # Skip if no valid assets are available\n",
    "        if X_train.shape[1] == 0 or X_test.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # # CARD\n",
    "        beta_card = card(X_train, y_train, kact)\n",
    "        te_card, to_card = evaluate_portfolio(X_test, y_test, beta_card)\n",
    "        results['CARD'].append({'date': stock_returns.index[start + train_window], 'te': te_card, 'to': to_card})\n",
    "        \n",
    "        # ALASSO\n",
    "        beta_alasso = alasso(X_train, y_train, kact)\n",
    "        te_alasso, to_alasso = evaluate_portfolio(X_test, y_test, beta_alasso)\n",
    "        results['ALASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_alasso, 'to': to_alasso})\n",
    "        \n",
    "        # # SLOPE-SLC\n",
    "        beta_slope_slc = slope_slc(X_train, y_train, kact, lambdas)\n",
    "        te_slope_slc, to_slope_slc = evaluate_portfolio(X_test, y_test, beta_slope_slc)\n",
    "        results['SLOPE-SLC'].append({'date': stock_returns.index[start + train_window], 'te': te_slope_slc, 'to': to_slope_slc})\n",
    "        \n",
    "        # # MSW-LASSO\n",
    "        beta_msw_lasso = msw_lasso(X_train, y_train, kact)\n",
    "        te_msw_lasso, to_msw_lasso = evaluate_portfolio(X_test, y_test, beta_msw_lasso)\n",
    "        results['MSW-LASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso, 'to': to_msw_lasso})\n",
    "        \n",
    "        print(f\"Window ending {stock_returns.index[start + train_window].date()}:\")\n",
    "        print(f\"CARD: TE={te_card:.4f}, TO={to_card:.4f}\")\n",
    "        print(f\"ALASSO: TE={te_alasso:.4f}, TO={to_alasso:.4f}\")\n",
    "        print(f\"SLOPE-SLC: TE={te_slope_slc:.4f}, TO={to_slope_slc:.4f}\")\n",
    "        print(f\"MSW-LASSO: TE={te_msw_lasso:.4f}, TO={to_msw_lasso:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "kact = 10\n",
    "lambdas = np.linspace(0.1, 1, stock_returns.shape[1]-1)  # Adjust as needed\n",
    "train_window = 250\n",
    "test_window =21\n",
    "\n",
    "# DATA usage\n",
    "X = stock_returns.drop(columns=['^GSPC'])\n",
    "y = stock_returns['^GSPC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the rolling window backtest\n",
    "results = rolling_window_backtest(X, y, train_window, test_window, kact, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df_results = {key: pd.DataFrame(val).set_index('date') for key, val in results.items()}\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['te'], label=f'{key} Tracking Error')\n",
    "\n",
    "plt.title('Tracking Error Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tracking Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['to'], label=f'{key} Turnover')\n",
    "\n",
    "plt.title('Turnover Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Turnover')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMIT(Rank Meets Index tracking model)\n",
    "\n",
    "1. RMIT model makes n samples of B(weight of porfolio) -> using n Regression model(with diffent randomn state or epoch)\n",
    "2. for n num of B it test tracking error using train set(1month? or 12 month?)\n",
    "3. for n num of B it test tracking error using valid set(1 month)\n",
    "4. compare rank between 2,3 and add it's loss == rank Loss + origin loss \n",
    "5. repeat 1~3 which add rank loss, stop when beta does not change(small then epsilon) \n",
    "-> for last choose best beta(smallest beta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rank_loss(rank_type, train_errors, valid_errors):\n",
    "    if rank_type == \"pointwise\":\n",
    "        return np.sum(np.abs(train_errors - valid_errors))\n",
    "    elif rank_type == \"pairwise\":\n",
    "        return np.sum((train_errors - valid_errors)**2)\n",
    "    elif rank_type == \"listwise\":\n",
    "        return np.sum((np.argsort(train_errors) - np.argsort(valid_errors))**2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rank_type. Choose from 'pointwise', 'pairwise', 'listwise'.\")\n",
    "\n",
    "def optimize_portfolio(X_train, y_train, lambdas, kact, epsilon=1e-5):\n",
    "    T, K = X_train.shape\n",
    "\n",
    "    # Initialize model\n",
    "    model = gp.Model(\"SLOPE\")\n",
    "    \n",
    "    # Variables\n",
    "    w = model.addVars(K, lb=-GRB.INFINITY, name=\"w\")\n",
    "    z = model.addVars(K, lb=0, name=\"z\")\n",
    "    u = model.addVars(K, lb=0, name=\"u\")\n",
    "    abs_w = model.addVars(K, vtype=GRB.BINARY, name=\"abs_w\")\n",
    "\n",
    "    # Constraints for absolute values and sorting\n",
    "    model.addConstrs((z[i] >= w[i] for i in range(K)), \"abs_pos\")\n",
    "    model.addConstrs((z[i] >= -w[i] for i in range(K)), \"abs_neg\")\n",
    "    model.addConstrs((u[i] == gp.quicksum(z[j] for j in range(i+1)) for i in range(K)), \"sort\")\n",
    "    \n",
    "    # Activation constraint\n",
    "    model.addConstr(gp.quicksum(abs_w[i] for i in range(K)) <= kact, \"kact_limit\")\n",
    "\n",
    "    # Linking constraint for abs_w and w\n",
    "    model.addConstrs((abs_w[i] >= w[i] / 1e-5 for i in range(K)), \"link_pos\")\n",
    "    model.addConstrs((abs_w[i] >= -w[i] / 1e-5 for i in range(K)), \"link_neg\")\n",
    "    model.addConstrs((abs_w[i] <= 1 for i in range(K)), \"link_bin\")\n",
    "\n",
    "    # Objective function\n",
    "    obj = (1/(2*T)) * gp.quicksum((y_train[t] - gp.quicksum(X_train[t,j]*w[j] for j in range(K)))**2 for t in range(T)) + \\\n",
    "          gp.quicksum(lambdas[i]*u[i] for i in range(K))\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Solve model\n",
    "    model.optimize()\n",
    "    \n",
    "    # Retrieve the optimal weights\n",
    "    w_opt = np.array([w[i].x for i in range(K)])\n",
    "    \n",
    "    return w_opt\n",
    "\n",
    "def RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha=0.1, theta=0.1, epsilon=1e-5, n_models=10, max_iter=100):\n",
    "    T, K = X_train.shape\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * K))) for i in range(1, K + 1)])\n",
    "\n",
    "    best_beta = None\n",
    "    best_loss = float('inf')\n",
    "    beta_change = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # 1. Generate n samples of B using n regression models\n",
    "        B_samples = []\n",
    "        for i in range(n_models):\n",
    "            model = Lasso(alpha=alpha, random_state=i)\n",
    "            model.fit(X_train, y_train)\n",
    "            B_samples.append(model.coef_)\n",
    "\n",
    "        # 2. Test tracking error using train set\n",
    "        train_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_train @ B\n",
    "            train_errors.append(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "        # 3. Test tracking error using valid set\n",
    "        valid_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_valid @ B\n",
    "            valid_errors.append(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "        # 4. Compare rank between train and valid errors and add its loss\n",
    "        rank_loss_value = rank_loss(rank_type, train_errors, valid_errors)\n",
    "\n",
    "        # Optimize with added rank loss\n",
    "        w_opt = optimize_portfolio(X_train, y_train, lambdas, kact, epsilon)\n",
    "        y_train_pred = X_train @ w_opt\n",
    "        origin_loss = mean_squared_error(y_train, y_train_pred)\n",
    "        total_loss = origin_loss + rank_loss_value\n",
    "\n",
    "        # 5. Repeat until beta does not change significantly\n",
    "        if best_loss - total_loss > epsilon:\n",
    "            best_loss = total_loss\n",
    "            best_beta = w_opt\n",
    "            beta_change = best_loss - total_loss\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_beta\n",
    "\n",
    "# Example usage:\n",
    "# X_train = np.array([...])  # Training set feature matrix\n",
    "# y_train = np.array([...])  # Training set target vector\n",
    "# X_valid = np.array([...])  # Validation set feature matrix\n",
    "# y_valid = np.array([...])  # Validation set target vector\n",
    "# kact = 10  # Number of active variables\n",
    "# rank_type = 'pointwise'  # Rank loss type ('pointwise', 'pairwise', 'listwise')\n",
    "# alpha = 0.1  # Regularization parameter\n",
    "# theta = 0.1  # Decay rate\n",
    "# epsilon = 1e-5  # Convergence threshold\n",
    "# n_models = 10  # Number of regression models\n",
    "# max_iter = 100  # Maximum number of iterations\n",
    "# best_beta = RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha, theta, epsilon, n_models, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
