{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stock data.\n",
    "file_path = '..\\data\\s&p500\\clean_s&p500_stock_data.csv'\n",
    "stock_data = pd.read_csv(file_path, index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>1268.800049</td>\n",
       "      <td>23.962805</td>\n",
       "      <td>37.450001</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.976089</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>58.470001</td>\n",
       "      <td>27.014999</td>\n",
       "      <td>39.288540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.804457</td>\n",
       "      <td>66.485435</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>76.480003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>1273.459961</td>\n",
       "      <td>24.027182</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>43.830002</td>\n",
       "      <td>2.677500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.004877</td>\n",
       "      <td>6.151111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.660000</td>\n",
       "      <td>58.570000</td>\n",
       "      <td>27.264999</td>\n",
       "      <td>39.235836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.948238</td>\n",
       "      <td>67.116508</td>\n",
       "      <td>42.410000</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>1273.479980</td>\n",
       "      <td>24.656652</td>\n",
       "      <td>39.709999</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>2.656429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.249577</td>\n",
       "      <td>6.061111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>58.279999</td>\n",
       "      <td>26.955000</td>\n",
       "      <td>38.814228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.670740</td>\n",
       "      <td>66.407768</td>\n",
       "      <td>42.529999</td>\n",
       "      <td>77.720001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>1285.449951</td>\n",
       "      <td>24.785408</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>2.725000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.619022</td>\n",
       "      <td>6.173333</td>\n",
       "      <td>...</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>59.430000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>38.577076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.620417</td>\n",
       "      <td>66.067963</td>\n",
       "      <td>44.119999</td>\n",
       "      <td>78.529999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>1290.150024</td>\n",
       "      <td>24.713877</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>44.560001</td>\n",
       "      <td>2.716071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.348318</td>\n",
       "      <td>6.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>27.645000</td>\n",
       "      <td>39.104084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.757010</td>\n",
       "      <td>68.407768</td>\n",
       "      <td>44.790001</td>\n",
       "      <td>77.879997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC          A        AAL        AAP      AAPL  ABBV  \\\n",
       "date                                                                       \n",
       "2006-01-03  1268.800049  23.962805  37.450001  43.520000  2.669643   NaN   \n",
       "2006-01-04  1273.459961  24.027182  39.200001  43.830002  2.677500   NaN   \n",
       "2006-01-05  1273.479980  24.656652  39.709999  44.040001  2.656429   NaN   \n",
       "2006-01-06  1285.449951  24.785408  39.000000  43.990002  2.725000   NaN   \n",
       "2006-01-09  1290.150024  24.713877  38.610001  44.560001  2.716071   NaN   \n",
       "\n",
       "             ABMD  ABS        ABT      ACGL  ...        XEL        XOM  \\\n",
       "date                                         ...                         \n",
       "2006-01-03   9.44  NaN  18.976089  6.120000  ...  18.570000  58.470001   \n",
       "2006-01-04   9.62  NaN  19.004877  6.151111  ...  18.660000  58.570000   \n",
       "2006-01-05   9.55  NaN  19.249577  6.061111  ...  18.650000  58.279999   \n",
       "2006-01-06   9.75  NaN  19.619022  6.173333  ...  18.719999  59.430000   \n",
       "2006-01-09  10.15  NaN  20.348318  6.116667  ...  18.670000  59.400002   \n",
       "\n",
       "                 XRAY        XRX  XYL        YUM        ZBH       ZBRA  \\\n",
       "date                                                                     \n",
       "2006-01-03  27.014999  39.288540  NaN  16.804457  66.485435  42.830002   \n",
       "2006-01-04  27.264999  39.235836  NaN  16.948238  67.116508  42.410000   \n",
       "2006-01-05  26.955000  38.814228  NaN  17.670740  66.407768  42.529999   \n",
       "2006-01-06  27.375000  38.577076  NaN  17.620417  66.067963  44.119999   \n",
       "2006-01-09  27.645000  39.104084  NaN  17.757010  68.407768  44.790001   \n",
       "\n",
       "                 ZION  ZTS  \n",
       "date                        \n",
       "2006-01-03  76.480003  NaN  \n",
       "2006-01-04  77.019997  NaN  \n",
       "2006-01-05  77.720001  NaN  \n",
       "2006-01-06  78.529999  NaN  \n",
       "2006-01-09  77.879997  NaN  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>3844.820068</td>\n",
       "      <td>149.229996</td>\n",
       "      <td>12.71</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>131.860001</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>63.380001</td>\n",
       "      <td>...</td>\n",
       "      <td>70.930000</td>\n",
       "      <td>108.680000</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>14.61</td>\n",
       "      <td>109.730003</td>\n",
       "      <td>128.899994</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>248.220001</td>\n",
       "      <td>48.450001</td>\n",
       "      <td>145.759995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>3829.250000</td>\n",
       "      <td>149.550003</td>\n",
       "      <td>12.53</td>\n",
       "      <td>145.020004</td>\n",
       "      <td>130.029999</td>\n",
       "      <td>162.990005</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.570000</td>\n",
       "      <td>63.619999</td>\n",
       "      <td>...</td>\n",
       "      <td>71.570000</td>\n",
       "      <td>110.190002</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>14.70</td>\n",
       "      <td>110.720001</td>\n",
       "      <td>129.899994</td>\n",
       "      <td>127.279999</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>48.840000</td>\n",
       "      <td>145.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>3783.219971</td>\n",
       "      <td>148.089996</td>\n",
       "      <td>12.32</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>162.229996</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.830002</td>\n",
       "      <td>62.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>70.570000</td>\n",
       "      <td>108.379997</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>14.37</td>\n",
       "      <td>108.940002</td>\n",
       "      <td>129.309998</td>\n",
       "      <td>125.989998</td>\n",
       "      <td>246.839996</td>\n",
       "      <td>47.970001</td>\n",
       "      <td>143.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>3849.280029</td>\n",
       "      <td>151.089996</td>\n",
       "      <td>12.70</td>\n",
       "      <td>146.309998</td>\n",
       "      <td>129.610001</td>\n",
       "      <td>162.559998</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.309998</td>\n",
       "      <td>63.110001</td>\n",
       "      <td>...</td>\n",
       "      <td>71.070000</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>32.279999</td>\n",
       "      <td>14.49</td>\n",
       "      <td>111.639999</td>\n",
       "      <td>129.990005</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>257.529999</td>\n",
       "      <td>49.080002</td>\n",
       "      <td>148.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>3839.500000</td>\n",
       "      <td>149.649994</td>\n",
       "      <td>12.72</td>\n",
       "      <td>147.029999</td>\n",
       "      <td>129.929993</td>\n",
       "      <td>161.610001</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.790001</td>\n",
       "      <td>62.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>70.110001</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>14.60</td>\n",
       "      <td>110.570000</td>\n",
       "      <td>128.080002</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>256.410004</td>\n",
       "      <td>49.160000</td>\n",
       "      <td>146.550003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC           A    AAL         AAP        AAPL  \\\n",
       "date                                                                 \n",
       "2022-12-23  3844.820068  149.229996  12.71  143.279999  131.860001   \n",
       "2022-12-27  3829.250000  149.550003  12.53  145.020004  130.029999   \n",
       "2022-12-28  3783.219971  148.089996  12.32  145.300003  126.040001   \n",
       "2022-12-29  3849.280029  151.089996  12.70  146.309998  129.610001   \n",
       "2022-12-30  3839.500000  149.649994  12.72  147.029999  129.929993   \n",
       "\n",
       "                  ABBV        ABMD  ABS         ABT       ACGL  ...  \\\n",
       "date                                                            ...   \n",
       "2022-12-23  163.100006  381.019989  NaN  108.180000  63.380001  ...   \n",
       "2022-12-27  162.990005  381.019989  NaN  108.570000  63.619999  ...   \n",
       "2022-12-28  162.229996  381.019989  NaN  107.830002  62.599998  ...   \n",
       "2022-12-29  162.559998  381.019989  NaN  110.309998  63.110001  ...   \n",
       "2022-12-30  161.610001  381.019989  NaN  109.790001  62.779999  ...   \n",
       "\n",
       "                  XEL         XOM       XRAY    XRX         XYL         YUM  \\\n",
       "date                                                                          \n",
       "2022-12-23  70.930000  108.680000  31.830000  14.61  109.730003  128.899994   \n",
       "2022-12-27  71.570000  110.190002  32.070000  14.70  110.720001  129.899994   \n",
       "2022-12-28  70.570000  108.379997  30.980000  14.37  108.940002  129.309998   \n",
       "2022-12-29  71.070000  109.199997  32.279999  14.49  111.639999  129.990005   \n",
       "2022-12-30  70.110001  110.300003  31.840000  14.60  110.570000  128.080002   \n",
       "\n",
       "                   ZBH        ZBRA       ZION         ZTS  \n",
       "date                                                       \n",
       "2022-12-23  126.690002  248.220001  48.450001  145.759995  \n",
       "2022-12-27  127.279999  251.000000  48.840000  145.300003  \n",
       "2022-12-28  125.989998  246.839996  47.970001  143.830002  \n",
       "2022-12-29  127.830002  257.529999  49.080002  148.149994  \n",
       "2022-12-30  127.500000  256.410004  49.160000  146.550003  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.014162</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.016760</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>-0.030685</td>\n",
       "      <td>-0.004663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006816</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.004542</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.007566</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.023139</td>\n",
       "      <td>0.030035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.002541</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.005844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013508</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-0.013631</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>-0.014693</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.004349</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>-0.010800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ^GSPC         A       AAL       AAP      AAPL      ABBV  ABMD  \\\n",
       "date                                                                           \n",
       "2022-12-23  0.005868  0.001476  0.011943  0.008446 -0.002798 -0.001041   0.0   \n",
       "2022-12-27 -0.004050  0.002144 -0.014162  0.012144 -0.013878 -0.000674   0.0   \n",
       "2022-12-28 -0.012021 -0.009763 -0.016760  0.001931 -0.030685 -0.004663   0.0   \n",
       "2022-12-29  0.017461  0.020258  0.030844  0.006951  0.028324  0.002034   0.0   \n",
       "2022-12-30 -0.002541 -0.009531  0.001575  0.004921  0.002469 -0.005844   0.0   \n",
       "\n",
       "            ABS       ABT      ACGL  ...       XEL       XOM      XRAY  \\\n",
       "date                                 ...                                 \n",
       "2022-12-23  0.0  0.001389  0.008433  ...  0.012852  0.026445  0.011118   \n",
       "2022-12-27  0.0  0.003605  0.003787  ...  0.009023  0.013894  0.007540   \n",
       "2022-12-28  0.0 -0.006816 -0.016033  ... -0.013972 -0.016426 -0.033988   \n",
       "2022-12-29  0.0  0.022999  0.008147  ...  0.007085  0.007566  0.041963   \n",
       "2022-12-30  0.0 -0.004714 -0.005229  ... -0.013508  0.010073 -0.013631   \n",
       "\n",
       "                 XRX       XYL       YUM       ZBH      ZBRA      ZION  \\\n",
       "date                                                                     \n",
       "2022-12-23 -0.003411 -0.000728  0.000621 -0.000789  0.002869  0.003521   \n",
       "2022-12-27  0.006160  0.009022  0.007758  0.004657  0.011200  0.008050   \n",
       "2022-12-28 -0.022449 -0.016077 -0.004542 -0.010135 -0.016574 -0.017813   \n",
       "2022-12-29  0.008351  0.024784  0.005259  0.014604  0.043307  0.023139   \n",
       "2022-12-30  0.007591 -0.009584 -0.014693 -0.002582 -0.004349  0.001630   \n",
       "\n",
       "                 ZTS  \n",
       "date                  \n",
       "2022-12-23  0.005033  \n",
       "2022-12-27 -0.003156  \n",
       "2022-12-28 -0.010117  \n",
       "2022-12-29  0.030035  \n",
       "2022-12-30 -0.010800  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate daily returns\n",
    "stock_returns = stock_data.pct_change().dropna(how='all')\n",
    "stock_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_returns['^GSPC'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment setup\n",
    "- daily return을 기준으로 index tracking 설정\n",
    "- 월별 리벨런싱 가정\n",
    "- 2006/01/01 ~ 2022-12/30\n",
    "- k act: 10% 20% 30% 40% 50% - 전체 주식의 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gurobi with adaptive loss 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Model fingerprint: 0xb1b4833e\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 2 rows, 2 columns, 4 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.0000000e+30   3.000000e+30   2.000000e+00      0s\n",
      "       2    3.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  3.000000000e+00\n",
      "Iteration 0, x: 2.0\n",
      "Iteration 0, y: 1.0\n",
      "Iteration 0, Obj: 3.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [3e+00, 3e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    9.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  9.000000000e+00\n",
      "Iteration 1, x: 2.0\n",
      "Iteration 1, y: 1.0\n",
      "Iteration 1, Obj: 9.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [9e+00, 9e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.7000000e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  2.700000000e+01\n",
      "Iteration 2, x: 2.0\n",
      "Iteration 2, y: 1.0\n",
      "Iteration 2, Obj: 27.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [3e+01, 3e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    8.1000000e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  8.100000000e+01\n",
      "Iteration 3, x: 2.0\n",
      "Iteration 3, y: 1.0\n",
      "Iteration 3, Obj: 81.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [8e+01, 8e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.4300000e+02   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  2.430000000e+02\n",
      "Iteration 4, x: 2.0\n",
      "Iteration 4, y: 1.0\n",
      "Iteration 4, Obj: 243.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+02, 2e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    7.2900000e+02   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  7.290000000e+02\n",
      "Iteration 5, x: 2.0\n",
      "Iteration 5, y: 1.0\n",
      "Iteration 5, Obj: 729.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [7e+02, 7e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.1870000e+03   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.04 seconds (0.00 work units)\n",
      "Optimal objective  2.187000000e+03\n",
      "Iteration 6, x: 2.0\n",
      "Iteration 6, y: 1.0\n",
      "Iteration 6, Obj: 2187.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+03, 2e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    6.5610000e+03   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  6.561000000e+03\n",
      "Iteration 7, x: 2.0\n",
      "Iteration 7, y: 1.0\n",
      "Iteration 7, Obj: 6561.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [7e+03, 7e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.9683000e+04   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.03 seconds (0.00 work units)\n",
      "Optimal objective  1.968300000e+04\n",
      "Iteration 8, x: 2.0\n",
      "Iteration 8, y: 1.0\n",
      "Iteration 8, Obj: 19683.0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 2 columns and 4 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e+04, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+00, 5e+00]\n",
      "LP warm-start: use basis\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    5.9049000e+04   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  5.904900000e+04\n",
      "Iteration 9, x: 2.0\n",
      "Iteration 9, y: 1.0\n",
      "Iteration 9, Obj: 59049.0\n",
      "Final x: 2.0\n",
      "Final y: 1.0\n",
      "Final Obj: 59049.0\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# 데이터 초기화\n",
    "max_iterations = 10  # 최대 반복 횟수\n",
    "epsilon = 1e-6  # 수렴 조건\n",
    "w = 1.0  # 초기 가중치\n",
    "previous_obj_value = float('inf')  # 초기 Objective Function 값\n",
    "\n",
    "# 모델 생성\n",
    "model = gp.Model(\"adaptive_weights\")\n",
    "\n",
    "# 변수 추가\n",
    "x = model.addVar(name=\"x\")\n",
    "y = model.addVar(name=\"y\")\n",
    "\n",
    "# 제약 조건 추가\n",
    "model.addConstr(x + 2 * y <= 4, \"c0\")\n",
    "model.addConstr(2 * x + y <= 5, \"c1\")\n",
    "\n",
    "# 반복 프로세스\n",
    "for iteration in range(max_iterations):\n",
    "    # 목표 함수 설정\n",
    "    model.setObjective(w * (x + y), GRB.MAXIMIZE)\n",
    "    \n",
    "    # 최적화 수행\n",
    "    model.optimize()\n",
    "    \n",
    "    # 결과 출력\n",
    "    if model.status == GRB.OPTIMAL or model.status == GRB.SUBOPTIMAL:\n",
    "        for v in model.getVars():\n",
    "            print(f'Iteration {iteration}, {v.varName}: {v.x}')\n",
    "        print(f'Iteration {iteration}, Obj: {model.objVal}')\n",
    "        \n",
    "        # 가중치 업데이트 (예: 목표 함수 값의 절대값을 가중치로 사용)\n",
    "        new_w = abs(model.objVal)\n",
    "        \n",
    "        # 수렴 확인\n",
    "        if abs(previous_obj_value - model.objVal) < epsilon:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        # 업데이트된 가중치 및 이전 목표 함수 값 갱신\n",
    "        w = new_w\n",
    "        previous_obj_value = model.objVal\n",
    "    else:\n",
    "        print(f\"Optimization was stopped at iteration {iteration}\")\n",
    "        break\n",
    "\n",
    "# 최종 결과 출력\n",
    "if model.status == GRB.OPTIMAL or model.status == GRB.SUBOPTIMAL:\n",
    "    for v in model.getVars():\n",
    "        print(f'Final {v.varName}: {v.x}')\n",
    "    print(f'Final Obj: {model.objVal}')\n",
    "else:\n",
    "    print(\"최적 해를 찾지 못했습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def card(X, y, kact, time_limit=1200, seed=42):\n",
    "#     #n number of row, day\n",
    "#     n, p = X.shape\n",
    "#     m = gp.Model()\n",
    "#     m.setParam('TimeLimit', time_limit)\n",
    "#     m.setParam(GRB.Param.Seed, seed)\n",
    "#     beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "#     z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    \n",
    "#     objective = (1/n) * ((y - X @ beta) @ (y - X @ beta))\n",
    "#     #objective 설정\n",
    "#     m.setObjective(objective, GRB.MINIMIZE)\n",
    "#     #constraint 0: z의 설정 beta가 0이 아니면 1로 설정\n",
    "#     m.addConstr(beta <= z, name=\"c0\")\n",
    "#     #constraint 1: full investment\n",
    "#     m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "#     #constraine 2: cardinality constraint\n",
    "#     m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "#     m.optimize()\n",
    "    \n",
    "#     return beta.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(X, y, kact, time_limit=1200):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) <= kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_stocks = stock_returns.drop(columns=['^GSPC'])\n",
    "stock_index = stock_returns['^GSPC']\n",
    "\n",
    "train_data = stock_stocks.iloc[:250]\n",
    "\n",
    "# Filter out columns with NaN values in the current window\n",
    "valid_assets_train = train_data.dropna(axis=1)\n",
    "valid_assets = valid_assets_train.columns.intersection(valid_assets_train.columns)\n",
    "\n",
    "X_train = valid_assets_train[valid_assets].values\n",
    "y_train = stock_index.iloc[:250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-07-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\cvxpy\\problems\\problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # CARD\n",
    "beta_card = card(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_card > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALASSO Algorithm\n",
    "- make initial beta using OLS\n",
    "- can not find propal lambda in the context\n",
    "- FIX!: ALASSO solution is always converge to 1,0,0,0 -> shrinking is too strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def alasso(X, y, kact, time_limit=1200, lambdas=1):\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Initial Lasso to get initial weights\n",
    "    lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "    lasso.fit(X, y)\n",
    "    beta_init = lasso.coef_\n",
    "    \n",
    "    # Adaptive weights\n",
    "    weights = 1 / (np.abs(beta_init) + 1e-6)\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + lambdas * cp.sum(weights @ cp.abs(beta)))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) == kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z  # Link binary variables with beta\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALASSO\n",
    "beta_alasso = alasso(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_alasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted LASSO- SLOPE\n",
    "detail is from Sparse index clones via the sorted l1-Norm\n",
    "SLOPE—ADAPTIVE VARIABLE SELECTION VIA CONVEX OPTIMIZATION\n",
    "\n",
    "- initial guess beta를 가지고 추정 시작\n",
    "- 이후 update\n",
    "- lambda of model: aplha(=sigma of model)(1-i*theta)~ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the lambda sequence\n",
    "def lambdas(beta_j, alpha, theta, p):\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * p))) for i in range(1, p + 1)])\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(X, y, kact, alpha=1.0, theta=0.1, time_limit=1200):\n",
    "    \"\"\"\n",
    "    Solve the SLOPE optimization problem using Gurobi with an activation constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like, shape (T, K)\n",
    "        The return matrix of benchmark constituents.\n",
    "    y : array-like, shape (T,)\n",
    "        The benchmark returns.\n",
    "    kact : int\n",
    "        Number of active variables (non-zero coefficients) allowed.\n",
    "    alpha : float, optional\n",
    "        Regularization parameter for the lambda sequence.\n",
    "    theta : float, optional\n",
    "        Decay rate for the lambda sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples and features\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    z = cp.Variable(p, boolean=True)  # Binary variables for cardinality constraint\n",
    "    sorted_abs_beta = cp.Variable(p, nonneg=True)\n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + cp.sum(cp.multiply(weights, sorted_abs_beta)))\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "        cp.sum(z) <= kact,  # Number of non-zero weights is less than or equal to kact\n",
    "        beta <= z,  # Link binary variables with beta\n",
    "    ]\n",
    "\n",
    "    #abs for DCP rules but beta is >=0 so we don't need absolute constraints\n",
    "    constraints += [sorted_abs_beta == beta]\n",
    "    # Sorting constraints\n",
    "    for i in range(p-1):\n",
    "        constraints.append(sorted_abs_beta[i] >= sorted_abs_beta[i+1])\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Strict inequalities are not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SLOPE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_slope \u001b[38;5;241m=\u001b[39m \u001b[43mslope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 42\u001b[0m, in \u001b[0;36mslope\u001b[1;34m(X, y, kact, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     41\u001b[0m     constraints\u001b[38;5;241m.\u001b[39mappend(sorted_beta[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m sorted_beta[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 42\u001b[0m constraints\u001b[38;5;241m.\u001b[39mappend(sorted_beta \u001b[38;5;241m==\u001b[39m cp\u001b[38;5;241m.\u001b[39mhstack(\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Problem definition\u001b[39;00m\n\u001b[0;32m     45\u001b[0m prob \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(objective, constraints)\n",
      "File \u001b[1;32mc:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\cvxpy\\expressions\\expression.py:762\u001b[0m, in \u001b[0;36mExpression.__lt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__lt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: ExpressionLike):\n\u001b[1;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrict inequalities are not allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Strict inequalities are not allowed."
     ]
    }
   ],
   "source": [
    "# SLOPE\n",
    "beta_slope = slope(X_train, y_train, kact=10, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_slope > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOPE-SLC\n",
    "1. Sorted LASSO의 변형 형태\n",
    "2. compute for each group the median partial correlation of consituents and keep only groups which are including 75th percent quantile for the equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_optimization_initial(X, y, alpha=1.0, theta=0.5, time_limit=1200): \n",
    "    n, p = X.shape\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * p))) for i in range(1, p + 1)])\n",
    "    \n",
    "    # Define variables\n",
    "    beta = cp.Variable(p)\n",
    "    sorted_abs_beta = cp.Variable(p)\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(cp.norm2(y - X @ beta) ** 2 + lambdas @ sorted_abs_beta)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(beta) == 1,  # Sum of weights is 1\n",
    "        beta >= 0,  # All weights beta are non-negative\n",
    "    ]\n",
    "    \n",
    "    # Absolute value constraints\n",
    "    constraints += [sorted_abs_beta >= beta, sorted_abs_beta >= -beta]\n",
    "    # Sorting constraints\n",
    "    constraints += [sorted_abs_beta[i] >= sorted_abs_beta[i+1] for i in range(p-1)]\n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(solver=cp.GUROBI, TimeLimit=time_limit)\n",
    "    \n",
    "    beta_opt = beta.value\n",
    "    \n",
    "    return beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_partial_correlation(X, y):\n",
    "    # Use LassoLarsIC to find significant features\n",
    "    model = LassoLarsIC(criterion='bic')\n",
    "    model.fit(X, y)\n",
    "    active_features = np.where(model.coef_ != 0)[0]\n",
    "    \n",
    "    partial_corr = np.zeros(X.shape[1])\n",
    "    for i in active_features:\n",
    "        residual_y = y - model.predict(X[:, active_features])\n",
    "        residual_x = X[:, i] - model.predict(X[:, active_features])\n",
    "        partial_corr[i] = np.corrcoef(residual_y, residual_x)[0, 1]\n",
    "    \n",
    "    return partial_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_slc_optimization(X, y, kact, alpha=1.0, theta=0.5, time_limit=1200):\n",
    "    \n",
    "    # Step 1: Solve SLOPE\n",
    "    beta_initial = slope_optimization_initial(X, y, alpha, theta, time_limit)\n",
    "    \n",
    "    # Step 2: Compute partial correlation for each asset\n",
    "    partial_corr = compute_partial_correlation(X, y)\n",
    "    \n",
    "    # Step 3: Select groups based on median partial correlation\n",
    "    median_corr = np.median(partial_corr)\n",
    "    threshold = np.percentile(partial_corr, 75)\n",
    "    active_indices = np.where(partial_corr >= threshold)[0]\n",
    "    \n",
    "    # Step 4: Rescale SLOPE estimates to sum to 1\n",
    "    beta_rescaled = np.zeros_like(beta_initial)\n",
    "    beta_rescaled[active_indices] = beta_initial[active_indices]\n",
    "    beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "    # Step 5: Ensure the number of active weights is less than or equal to kact\n",
    "    if np.sum(beta_rescaled > 0) > kact:\n",
    "        sorted_indices = np.argsort(beta_rescaled)[::-1]\n",
    "        beta_rescaled[sorted_indices[kact:]] = 0\n",
    "        beta_rescaled /= np.sum(beta_rescaled)\n",
    "    \n",
    "    return beta_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cvxpy' has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SLOPE-SLC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_slope_slc \u001b[38;5;241m=\u001b[39m \u001b[43mslope_slc_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m, in \u001b[0;36mslope_slc_optimization\u001b[1;34m(X, y, kact, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslope_slc_optimization\u001b[39m(X, y, kact, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1200\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Step 1: Solve SLOPE\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     beta_initial \u001b[38;5;241m=\u001b[39m \u001b[43mslope_optimization_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: Compute partial correlation for each asset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     partial_corr \u001b[38;5;241m=\u001b[39m compute_partial_correlation(X, y)\n",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m, in \u001b[0;36mslope_optimization_initial\u001b[1;34m(X, y, alpha, theta, time_limit)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Sorting constraints\u001b[39;00m\n\u001b[0;32m     23\u001b[0m constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [sorted_abs_beta[i] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m sorted_abs_beta[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m---> 24\u001b[0m constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [sorted_abs_beta \u001b[38;5;241m==\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m(abs_beta, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Problem definition\u001b[39;00m\n\u001b[0;32m     27\u001b[0m prob \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(objective, constraints)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cvxpy' has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "# SLOPE-SLC\n",
    "beta_slope_slc = slope_slc_optimization(X_train, y_train, kact=10, time_limit=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_negative_count = np.sum(beta_slope_slc > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSW_LASSO\n",
    "detail is from High-dimensional Sprase index tracking based on a multi-step coonvex optimization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msw_lasso(X, y, kact, max_iter=100, tol=1e-12, penalty='MCP', a=2.5, time_limit = 1200, seed=42):\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    \n",
    "    def p_lambda(beta_j, lam, a):\n",
    "        #MCP: b, a =2.5\n",
    "        #SCAD: a=3.7\n",
    "        #log-M: epsilon = 1.67*10^-5\n",
    "        #lq: q=0.1\n",
    "        if penalty == 'MCP':\n",
    "            b = a \n",
    "            return lam * beta_j - (beta_j**2) / (2 * b) if beta_j <= b * lam else (b * lam**2) / 2\n",
    "        elif penalty == 'SCAD':\n",
    "            if beta_j <= lam:\n",
    "                return lam * beta_j\n",
    "            elif beta_j <= a * lam:\n",
    "                return (-beta_j**2 + 2 * a * lam * beta_j - lam**2) / (2 * (a - 1))\n",
    "            else:\n",
    "                return (a + 1) * lam**2 / 2\n",
    "        elif penalty == 'log-M':\n",
    "            eps = a\n",
    "            return lam * np.log(1+np.abs(beta_j)/eps) / np.log(1+(1/eps))\n",
    "        elif penalty == 'lq':\n",
    "            q = a \n",
    "            return lam * (abs(beta_j) **q) \n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        m.reset()   \n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "        beta_value = beta.X\n",
    "        # 결과 출력\n",
    "        if m.status == GRB.OPTIMAL or m.status == GRB.SUBOPTIMAL:\n",
    "            beta_value = beta.X\n",
    "            new_weights = np.array([abs(p_lambda(beta_value[j], 1, a)) for j in range(p)])\n",
    "            weights = new_weights\n",
    "            \n",
    "            if np.linalg.norm(new_weights - weights) < tol:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x63bfc5c1\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0007714\n",
      "Presolve time: 0.06s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 6330 iterations, 2.30 seconds (2.20 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.0001054    1.00000  0.01%     -    2s\n",
      "H    0     0                       1.0000058    1.00000  0.00%     -    2s\n",
      "     0     0    1.00000    0  103    1.00001    1.00000  0.00%     -    2s\n",
      "\n",
      "Explored 1 nodes (6330 simplex iterations) in 2.51 seconds (2.21 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.00001 1.00011 1.00077 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000005843494e+00, best bound 1.000000110964e+00, gap 0.0006%\n"
     ]
    }
   ],
   "source": [
    "# # msw_lasso\n",
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=20, penalty='MCP', a=2.5, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x301ba4af\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0007714\n",
      "Presolve time: 0.06s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 6330 iterations, 1.67 seconds (2.20 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.0001054    1.00000  0.01%     -    1s\n",
      "H    0     0                       1.0000151    1.00000  0.00%     -    1s\n",
      "     0     0    1.00000    0  103    1.00002    1.00000  0.00%     -    1s\n",
      "\n",
      "Explored 1 nodes (6330 simplex iterations) in 1.90 seconds (2.21 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.00002 1.00011 1.00077 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000015133005e+00, best bound 1.000000110964e+00, gap 0.0015%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='SCAD', a=3.7, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x301ba4af\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0007714\n",
      "Presolve time: 0.09s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 6330 iterations, 2.82 seconds (2.20 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.0001054    1.00000  0.01%     -    3s\n",
      "H    0     0                       1.0000151    1.00000  0.00%     -    3s\n",
      "     0     0    1.00000    0  103    1.00002    1.00000  0.00%     -    3s\n",
      "\n",
      "Explored 1 nodes (6330 simplex iterations) in 3.13 seconds (2.21 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.00002 1.00011 1.00077 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000015133005e+00, best bound 1.000000110964e+00, gap 0.0015%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='log-M', a=1.67*(10**-5), max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Discarded solution information\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x301ba4af\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.0007714\n",
      "Presolve time: 0.06s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 6330 iterations, 2.66 seconds (2.20 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       1.0001054    1.00000  0.01%     -    2s\n",
      "H    0     0                       1.0000151    1.00000  0.00%     -    2s\n",
      "     0     0    1.00000    0  103    1.00002    1.00000  0.00%     -    2s\n",
      "\n",
      "Explored 1 nodes (6330 simplex iterations) in 2.89 seconds (2.21 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.00002 1.00011 1.00077 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000015133005e+00, best bound 1.000000110964e+00, gap 0.0015%\n"
     ]
    }
   ],
   "source": [
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10, penalty='lq', a=0.1, max_iter=3, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest\n",
    "## Experiment result \n",
    "- Turn over 비용\n",
    "- Tracking error(for out of sample)\n",
    "- Computing time(running time second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(X, y, beta):\n",
    "    tracking_error = np.sqrt(np.mean((y - X @ beta)**2))\n",
    "    turnover = np.sum(np.abs(beta[1:] - beta[:-1])) / len(beta)\n",
    "    return tracking_error, turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_backtest(stock_returns, stock_index, train_window, test_window, kact, lambdas):\n",
    "    results = {'CARD': [], 'ALASSO': [], 'SLOPE-SLC': [], 'MSW-LASSO': []}\n",
    "    n = len(stock_returns)\n",
    "    \n",
    "    for start in range(0, n - train_window - test_window + 1, test_window):\n",
    "        train_data = stock_returns.iloc[start:start + train_window]\n",
    "        test_data = stock_returns.iloc[start + train_window:start + train_window + test_window]\n",
    "    \n",
    "        # Filter out columns with NaN values in the current window\n",
    "        valid_assets_train = train_data.dropna(axis=1)\n",
    "        valid_assets_test = test_data.dropna(axis=1)\n",
    "        valid_assets = valid_assets_train.columns.intersection(valid_assets_test.columns)\n",
    "        \n",
    "        X_train = valid_assets_train[valid_assets].values\n",
    "        y_train = stock_index.iloc[start:start + train_window].values\n",
    "        \n",
    "        X_test = valid_assets_test[valid_assets].values\n",
    "        y_test = stock_index.iloc[start + train_window:start + train_window + test_window].values\n",
    "        # Skip if no valid assets are available\n",
    "        if X_train.shape[1] == 0 or X_test.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # # CARD\n",
    "        beta_card = card(X_train, y_train, kact)\n",
    "        te_card, to_card = evaluate_portfolio(X_test, y_test, beta_card)\n",
    "        results['CARD'].append({'date': stock_returns.index[start + train_window], 'te': te_card, 'to': to_card})\n",
    "        \n",
    "        # ALASSO\n",
    "        beta_alasso = alasso(X_train, y_train, kact)\n",
    "        te_alasso, to_alasso = evaluate_portfolio(X_test, y_test, beta_alasso)\n",
    "        results['ALASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_alasso, 'to': to_alasso})\n",
    "        \n",
    "        # # SLOPE-SLC\n",
    "        beta_slope_slc = slope_slc(X_train, y_train, kact, lambdas)\n",
    "        te_slope_slc, to_slope_slc = evaluate_portfolio(X_test, y_test, beta_slope_slc)\n",
    "        results['SLOPE-SLC'].append({'date': stock_returns.index[start + train_window], 'te': te_slope_slc, 'to': to_slope_slc})\n",
    "        \n",
    "        # # MSW-LASSO\n",
    "        beta_msw_lasso = msw_lasso(X_train, y_train, kact)\n",
    "        te_msw_lasso, to_msw_lasso = evaluate_portfolio(X_test, y_test, beta_msw_lasso)\n",
    "        results['MSW-LASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso, 'to': to_msw_lasso})\n",
    "        \n",
    "        print(f\"Window ending {stock_returns.index[start + train_window].date()}:\")\n",
    "        print(f\"CARD: TE={te_card:.4f}, TO={to_card:.4f}\")\n",
    "        print(f\"ALASSO: TE={te_alasso:.4f}, TO={to_alasso:.4f}\")\n",
    "        print(f\"SLOPE-SLC: TE={te_slope_slc:.4f}, TO={to_slope_slc:.4f}\")\n",
    "        print(f\"MSW-LASSO: TE={te_msw_lasso:.4f}, TO={to_msw_lasso:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "kact = 10\n",
    "lambdas = np.linspace(0.1, 1, stock_returns.shape[1]-1)  # Adjust as needed\n",
    "train_window = 250\n",
    "test_window =21\n",
    "\n",
    "# DATA usage\n",
    "X = stock_returns.drop(columns=['^GSPC'])\n",
    "y = stock_returns['^GSPC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the rolling window backtest\n",
    "results = rolling_window_backtest(X, y, train_window, test_window, kact, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df_results = {key: pd.DataFrame(val).set_index('date') for key, val in results.items()}\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['te'], label=f'{key} Tracking Error')\n",
    "\n",
    "plt.title('Tracking Error Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tracking Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['to'], label=f'{key} Turnover')\n",
    "\n",
    "plt.title('Turnover Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Turnover')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMIT(Rank Meets Index tracking model)\n",
    "\n",
    "1. RMIT model makes n samples of B(weight of porfolio) -> using n Regression model(with diffent randomn state or epoch)\n",
    "2. for n num of B it test tracking error using train set(1month? or 12 month?)\n",
    "3. for n num of B it test tracking error using valid set(1 month)\n",
    "4. compare rank between 2,3 and add it's loss == rank Loss + origin loss \n",
    "5. repeat 1~3 which add rank loss, stop when beta does not change(small then epsilon) \n",
    "-> for last choose best beta(smallest beta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rank_loss(rank_type, train_errors, valid_errors):\n",
    "    if rank_type == \"pointwise\":\n",
    "        return np.sum(np.abs(train_errors - valid_errors))\n",
    "    elif rank_type == \"pairwise\":\n",
    "        return np.sum((train_errors - valid_errors)**2)\n",
    "    elif rank_type == \"listwise\":\n",
    "        return np.sum((np.argsort(train_errors) - np.argsort(valid_errors))**2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rank_type. Choose from 'pointwise', 'pairwise', 'listwise'.\")\n",
    "\n",
    "def optimize_portfolio(X_train, y_train, lambdas, kact, epsilon=1e-5):\n",
    "    T, K = X_train.shape\n",
    "\n",
    "    # Initialize model\n",
    "    model = gp.Model(\"SLOPE\")\n",
    "    \n",
    "    # Variables\n",
    "    w = model.addVars(K, lb=-GRB.INFINITY, name=\"w\")\n",
    "    z = model.addVars(K, lb=0, name=\"z\")\n",
    "    u = model.addVars(K, lb=0, name=\"u\")\n",
    "    abs_w = model.addVars(K, vtype=GRB.BINARY, name=\"abs_w\")\n",
    "\n",
    "    # Constraints for absolute values and sorting\n",
    "    model.addConstrs((z[i] >= w[i] for i in range(K)), \"abs_pos\")\n",
    "    model.addConstrs((z[i] >= -w[i] for i in range(K)), \"abs_neg\")\n",
    "    model.addConstrs((u[i] == gp.quicksum(z[j] for j in range(i+1)) for i in range(K)), \"sort\")\n",
    "    \n",
    "    # Activation constraint\n",
    "    model.addConstr(gp.quicksum(abs_w[i] for i in range(K)) <= kact, \"kact_limit\")\n",
    "\n",
    "    # Linking constraint for abs_w and w\n",
    "    model.addConstrs((abs_w[i] >= w[i] / 1e-5 for i in range(K)), \"link_pos\")\n",
    "    model.addConstrs((abs_w[i] >= -w[i] / 1e-5 for i in range(K)), \"link_neg\")\n",
    "    model.addConstrs((abs_w[i] <= 1 for i in range(K)), \"link_bin\")\n",
    "\n",
    "    # Objective function\n",
    "    obj = (1/(2*T)) * gp.quicksum((y_train[t] - gp.quicksum(X_train[t,j]*w[j] for j in range(K)))**2 for t in range(T)) + \\\n",
    "          gp.quicksum(lambdas[i]*u[i] for i in range(K))\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Solve model\n",
    "    model.optimize()\n",
    "    \n",
    "    # Retrieve the optimal weights\n",
    "    w_opt = np.array([w[i].x for i in range(K)])\n",
    "    \n",
    "    return w_opt\n",
    "\n",
    "def RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha=0.1, theta=0.1, epsilon=1e-5, n_models=10, max_iter=100):\n",
    "    T, K = X_train.shape\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * K))) for i in range(1, K + 1)])\n",
    "\n",
    "    best_beta = None\n",
    "    best_loss = float('inf')\n",
    "    beta_change = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # 1. Generate n samples of B using n regression models\n",
    "        B_samples = []\n",
    "        for i in range(n_models):\n",
    "            model = Lasso(alpha=alpha, random_state=i)\n",
    "            model.fit(X_train, y_train)\n",
    "            B_samples.append(model.coef_)\n",
    "\n",
    "        # 2. Test tracking error using train set\n",
    "        train_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_train @ B\n",
    "            train_errors.append(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "        # 3. Test tracking error using valid set\n",
    "        valid_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_valid @ B\n",
    "            valid_errors.append(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "        # 4. Compare rank between train and valid errors and add its loss\n",
    "        rank_loss_value = rank_loss(rank_type, train_errors, valid_errors)\n",
    "\n",
    "        # Optimize with added rank loss\n",
    "        w_opt = optimize_portfolio(X_train, y_train, lambdas, kact, epsilon)\n",
    "        y_train_pred = X_train @ w_opt\n",
    "        origin_loss = mean_squared_error(y_train, y_train_pred)\n",
    "        total_loss = origin_loss + rank_loss_value\n",
    "\n",
    "        # 5. Repeat until beta does not change significantly\n",
    "        if best_loss - total_loss > epsilon:\n",
    "            best_loss = total_loss\n",
    "            best_beta = w_opt\n",
    "            beta_change = best_loss - total_loss\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_beta\n",
    "\n",
    "# Example usage:\n",
    "# X_train = np.array([...])  # Training set feature matrix\n",
    "# y_train = np.array([...])  # Training set target vector\n",
    "# X_valid = np.array([...])  # Validation set feature matrix\n",
    "# y_valid = np.array([...])  # Validation set target vector\n",
    "# kact = 10  # Number of active variables\n",
    "# rank_type = 'pointwise'  # Rank loss type ('pointwise', 'pairwise', 'listwise')\n",
    "# alpha = 0.1  # Regularization parameter\n",
    "# theta = 0.1  # Decay rate\n",
    "# epsilon = 1e-5  # Convergence threshold\n",
    "# n_models = 10  # Number of regression models\n",
    "# max_iter = 100  # Maximum number of iterations\n",
    "# best_beta = RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha, theta, epsilon, n_models, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
