{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxopt import matrix, solvers\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stock data.\n",
    "file_path = '.\\data\\s&p500\\clean_s&p500_stock_data.csv'\n",
    "stock_data = pd.read_csv(file_path, index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>1268.800049</td>\n",
       "      <td>23.962805</td>\n",
       "      <td>37.450001</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>2.669643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.976089</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>58.470001</td>\n",
       "      <td>27.014999</td>\n",
       "      <td>39.288540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.804457</td>\n",
       "      <td>66.485435</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>76.480003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>1273.459961</td>\n",
       "      <td>24.027182</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>43.830002</td>\n",
       "      <td>2.677500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.004877</td>\n",
       "      <td>6.151111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.660000</td>\n",
       "      <td>58.570000</td>\n",
       "      <td>27.264999</td>\n",
       "      <td>39.235836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.948238</td>\n",
       "      <td>67.116508</td>\n",
       "      <td>42.410000</td>\n",
       "      <td>77.019997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>1273.479980</td>\n",
       "      <td>24.656652</td>\n",
       "      <td>39.709999</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>2.656429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.249577</td>\n",
       "      <td>6.061111</td>\n",
       "      <td>...</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>58.279999</td>\n",
       "      <td>26.955000</td>\n",
       "      <td>38.814228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.670740</td>\n",
       "      <td>66.407768</td>\n",
       "      <td>42.529999</td>\n",
       "      <td>77.720001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>1285.449951</td>\n",
       "      <td>24.785408</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>2.725000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.619022</td>\n",
       "      <td>6.173333</td>\n",
       "      <td>...</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>59.430000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>38.577076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.620417</td>\n",
       "      <td>66.067963</td>\n",
       "      <td>44.119999</td>\n",
       "      <td>78.529999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>1290.150024</td>\n",
       "      <td>24.713877</td>\n",
       "      <td>38.610001</td>\n",
       "      <td>44.560001</td>\n",
       "      <td>2.716071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.348318</td>\n",
       "      <td>6.116667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>27.645000</td>\n",
       "      <td>39.104084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.757010</td>\n",
       "      <td>68.407768</td>\n",
       "      <td>44.790001</td>\n",
       "      <td>77.879997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC          A        AAL        AAP      AAPL  ABBV  \\\n",
       "date                                                                       \n",
       "2006-01-03  1268.800049  23.962805  37.450001  43.520000  2.669643   NaN   \n",
       "2006-01-04  1273.459961  24.027182  39.200001  43.830002  2.677500   NaN   \n",
       "2006-01-05  1273.479980  24.656652  39.709999  44.040001  2.656429   NaN   \n",
       "2006-01-06  1285.449951  24.785408  39.000000  43.990002  2.725000   NaN   \n",
       "2006-01-09  1290.150024  24.713877  38.610001  44.560001  2.716071   NaN   \n",
       "\n",
       "             ABMD  ABS        ABT      ACGL  ...        XEL        XOM  \\\n",
       "date                                         ...                         \n",
       "2006-01-03   9.44  NaN  18.976089  6.120000  ...  18.570000  58.470001   \n",
       "2006-01-04   9.62  NaN  19.004877  6.151111  ...  18.660000  58.570000   \n",
       "2006-01-05   9.55  NaN  19.249577  6.061111  ...  18.650000  58.279999   \n",
       "2006-01-06   9.75  NaN  19.619022  6.173333  ...  18.719999  59.430000   \n",
       "2006-01-09  10.15  NaN  20.348318  6.116667  ...  18.670000  59.400002   \n",
       "\n",
       "                 XRAY        XRX  XYL        YUM        ZBH       ZBRA  \\\n",
       "date                                                                     \n",
       "2006-01-03  27.014999  39.288540  NaN  16.804457  66.485435  42.830002   \n",
       "2006-01-04  27.264999  39.235836  NaN  16.948238  67.116508  42.410000   \n",
       "2006-01-05  26.955000  38.814228  NaN  17.670740  66.407768  42.529999   \n",
       "2006-01-06  27.375000  38.577076  NaN  17.620417  66.067963  44.119999   \n",
       "2006-01-09  27.645000  39.104084  NaN  17.757010  68.407768  44.790001   \n",
       "\n",
       "                 ZION  ZTS  \n",
       "date                        \n",
       "2006-01-03  76.480003  NaN  \n",
       "2006-01-04  77.019997  NaN  \n",
       "2006-01-05  77.720001  NaN  \n",
       "2006-01-06  78.529999  NaN  \n",
       "2006-01-09  77.879997  NaN  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>3844.820068</td>\n",
       "      <td>149.229996</td>\n",
       "      <td>12.71</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>131.860001</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>63.380001</td>\n",
       "      <td>...</td>\n",
       "      <td>70.930000</td>\n",
       "      <td>108.680000</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>14.61</td>\n",
       "      <td>109.730003</td>\n",
       "      <td>128.899994</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>248.220001</td>\n",
       "      <td>48.450001</td>\n",
       "      <td>145.759995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>3829.250000</td>\n",
       "      <td>149.550003</td>\n",
       "      <td>12.53</td>\n",
       "      <td>145.020004</td>\n",
       "      <td>130.029999</td>\n",
       "      <td>162.990005</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.570000</td>\n",
       "      <td>63.619999</td>\n",
       "      <td>...</td>\n",
       "      <td>71.570000</td>\n",
       "      <td>110.190002</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>14.70</td>\n",
       "      <td>110.720001</td>\n",
       "      <td>129.899994</td>\n",
       "      <td>127.279999</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>48.840000</td>\n",
       "      <td>145.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>3783.219971</td>\n",
       "      <td>148.089996</td>\n",
       "      <td>12.32</td>\n",
       "      <td>145.300003</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>162.229996</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.830002</td>\n",
       "      <td>62.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>70.570000</td>\n",
       "      <td>108.379997</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>14.37</td>\n",
       "      <td>108.940002</td>\n",
       "      <td>129.309998</td>\n",
       "      <td>125.989998</td>\n",
       "      <td>246.839996</td>\n",
       "      <td>47.970001</td>\n",
       "      <td>143.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>3849.280029</td>\n",
       "      <td>151.089996</td>\n",
       "      <td>12.70</td>\n",
       "      <td>146.309998</td>\n",
       "      <td>129.610001</td>\n",
       "      <td>162.559998</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.309998</td>\n",
       "      <td>63.110001</td>\n",
       "      <td>...</td>\n",
       "      <td>71.070000</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>32.279999</td>\n",
       "      <td>14.49</td>\n",
       "      <td>111.639999</td>\n",
       "      <td>129.990005</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>257.529999</td>\n",
       "      <td>49.080002</td>\n",
       "      <td>148.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>3839.500000</td>\n",
       "      <td>149.649994</td>\n",
       "      <td>12.72</td>\n",
       "      <td>147.029999</td>\n",
       "      <td>129.929993</td>\n",
       "      <td>161.610001</td>\n",
       "      <td>381.019989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.790001</td>\n",
       "      <td>62.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>70.110001</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>14.60</td>\n",
       "      <td>110.570000</td>\n",
       "      <td>128.080002</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>256.410004</td>\n",
       "      <td>49.160000</td>\n",
       "      <td>146.550003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ^GSPC           A    AAL         AAP        AAPL  \\\n",
       "date                                                                 \n",
       "2022-12-23  3844.820068  149.229996  12.71  143.279999  131.860001   \n",
       "2022-12-27  3829.250000  149.550003  12.53  145.020004  130.029999   \n",
       "2022-12-28  3783.219971  148.089996  12.32  145.300003  126.040001   \n",
       "2022-12-29  3849.280029  151.089996  12.70  146.309998  129.610001   \n",
       "2022-12-30  3839.500000  149.649994  12.72  147.029999  129.929993   \n",
       "\n",
       "                  ABBV        ABMD  ABS         ABT       ACGL  ...  \\\n",
       "date                                                            ...   \n",
       "2022-12-23  163.100006  381.019989  NaN  108.180000  63.380001  ...   \n",
       "2022-12-27  162.990005  381.019989  NaN  108.570000  63.619999  ...   \n",
       "2022-12-28  162.229996  381.019989  NaN  107.830002  62.599998  ...   \n",
       "2022-12-29  162.559998  381.019989  NaN  110.309998  63.110001  ...   \n",
       "2022-12-30  161.610001  381.019989  NaN  109.790001  62.779999  ...   \n",
       "\n",
       "                  XEL         XOM       XRAY    XRX         XYL         YUM  \\\n",
       "date                                                                          \n",
       "2022-12-23  70.930000  108.680000  31.830000  14.61  109.730003  128.899994   \n",
       "2022-12-27  71.570000  110.190002  32.070000  14.70  110.720001  129.899994   \n",
       "2022-12-28  70.570000  108.379997  30.980000  14.37  108.940002  129.309998   \n",
       "2022-12-29  71.070000  109.199997  32.279999  14.49  111.639999  129.990005   \n",
       "2022-12-30  70.110001  110.300003  31.840000  14.60  110.570000  128.080002   \n",
       "\n",
       "                   ZBH        ZBRA       ZION         ZTS  \n",
       "date                                                       \n",
       "2022-12-23  126.690002  248.220001  48.450001  145.759995  \n",
       "2022-12-27  127.279999  251.000000  48.840000  145.300003  \n",
       "2022-12-28  125.989998  246.839996  47.970001  143.830002  \n",
       "2022-12-29  127.830002  257.529999  49.080002  148.149994  \n",
       "2022-12-30  127.500000  256.410004  49.160000  146.550003  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABS</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.005033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>-0.014162</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.016760</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>-0.030685</td>\n",
       "      <td>-0.004663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006816</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>-0.016426</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.004542</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.007566</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.023139</td>\n",
       "      <td>0.030035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.002541</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.005844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013508</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-0.013631</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>-0.014693</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.004349</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>-0.010800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ^GSPC         A       AAL       AAP      AAPL      ABBV  ABMD  \\\n",
       "date                                                                           \n",
       "2022-12-23  0.005868  0.001476  0.011943  0.008446 -0.002798 -0.001041   0.0   \n",
       "2022-12-27 -0.004050  0.002144 -0.014162  0.012144 -0.013878 -0.000674   0.0   \n",
       "2022-12-28 -0.012021 -0.009763 -0.016760  0.001931 -0.030685 -0.004663   0.0   \n",
       "2022-12-29  0.017461  0.020258  0.030844  0.006951  0.028324  0.002034   0.0   \n",
       "2022-12-30 -0.002541 -0.009531  0.001575  0.004921  0.002469 -0.005844   0.0   \n",
       "\n",
       "            ABS       ABT      ACGL  ...       XEL       XOM      XRAY  \\\n",
       "date                                 ...                                 \n",
       "2022-12-23  0.0  0.001389  0.008433  ...  0.012852  0.026445  0.011118   \n",
       "2022-12-27  0.0  0.003605  0.003787  ...  0.009023  0.013894  0.007540   \n",
       "2022-12-28  0.0 -0.006816 -0.016033  ... -0.013972 -0.016426 -0.033988   \n",
       "2022-12-29  0.0  0.022999  0.008147  ...  0.007085  0.007566  0.041963   \n",
       "2022-12-30  0.0 -0.004714 -0.005229  ... -0.013508  0.010073 -0.013631   \n",
       "\n",
       "                 XRX       XYL       YUM       ZBH      ZBRA      ZION  \\\n",
       "date                                                                     \n",
       "2022-12-23 -0.003411 -0.000728  0.000621 -0.000789  0.002869  0.003521   \n",
       "2022-12-27  0.006160  0.009022  0.007758  0.004657  0.011200  0.008050   \n",
       "2022-12-28 -0.022449 -0.016077 -0.004542 -0.010135 -0.016574 -0.017813   \n",
       "2022-12-29  0.008351  0.024784  0.005259  0.014604  0.043307  0.023139   \n",
       "2022-12-30  0.007591 -0.009584 -0.014693 -0.002582 -0.004349  0.001630   \n",
       "\n",
       "                 ZTS  \n",
       "date                  \n",
       "2022-12-23  0.005033  \n",
       "2022-12-27 -0.003156  \n",
       "2022-12-28 -0.010117  \n",
       "2022-12-29  0.030035  \n",
       "2022-12-30 -0.010800  \n",
       "\n",
       "[5 rows x 705 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate daily returns\n",
    "stock_returns = stock_data.pct_change().dropna(how='all')\n",
    "stock_returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_returns['^GSPC'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment setup\n",
    "- daily return을 기준으로 index tracking 설정\n",
    "- 월별 리벨런싱 가정\n",
    "- 2006/01/01 ~ 2022-12/30\n",
    "- k act: 10% 20% 30% 40% 50% - 전체 주식의 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def card(X, y, kact, time_limit=1200, seed=42):\n",
    "    #n number of row, day\n",
    "    n, p = X.shape\n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "    m.setParam(GRB.Param.Seed, seed)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "    \n",
    "    objective = (1/n) * ((y - X @ beta) @ (y - X @ beta))\n",
    "    #objective 설정\n",
    "    m.setObjective(objective, GRB.MINIMIZE)\n",
    "    #constraint 0: z의 설정 beta가 0이 아니면 1로 설정\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    #constraint 1: full investment\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    #constraine 2: cardinality constraint\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    return beta.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_stocks = stock_returns.drop(columns=['^GSPC'])\n",
    "stock_index = stock_returns['^GSPC']\n",
    "\n",
    "train_data = stock_stocks.iloc[:250]\n",
    "\n",
    "# Filter out columns with NaN values in the current window\n",
    "valid_assets_train = train_data.dropna(axis=1)\n",
    "valid_assets = valid_assets_train.columns.intersection(valid_assets_train.columns)\n",
    "\n",
    "X_train = valid_assets_train[valid_assets].values\n",
    "y_train = stock_index.iloc[:250].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 60\n",
      "Set parameter Seed to value 42\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x0f2c00e8\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 2e-02]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 0.0007714\n",
      "Presolve time: 0.05s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.140279e-07, 4355 iterations, 0.35 seconds (0.88 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                       0.0001054    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0  106    0.00011    0.00000   100%     -    0s\n",
      "H    0     0                       0.0000162    0.00000  99.3%     -    0s\n",
      "H    0     0                       0.0000153    0.00000  99.3%     -    0s\n",
      "H    0     0                       0.0000133    0.00000  99.1%     -    1s\n",
      "H    0     0                       0.0000121    0.00000  99.1%     -    1s\n",
      "     0     0    0.00000    0  106    0.00001    0.00000  99.1%     -    1s\n",
      "H    0     0                       0.0000056    0.00000  98.0%     -    1s\n",
      "H    0     0                       0.0000038    0.00000  97.0%     -    2s\n",
      "     0     2    0.00000    0  106    0.00000    0.00000  97.0%     -    2s\n",
      "    15    20    0.00000    5  114    0.00000    0.00000  97.0%   620    5s\n",
      "H   28    32                       0.0000037    0.00000  97.0%   484    6s\n",
      "H   29    32                       0.0000037    0.00000  96.9%   471    6s\n",
      "    47    72    0.00000   13  116    0.00000    0.00000  96.9%   438   10s\n",
      "H   71    92                       0.0000034    0.00000  96.6%   379   12s\n",
      "H  157   191                       0.0000034    0.00000  96.6%   253   16s\n",
      "H  168   191                       0.0000033    0.00000  96.5%   246   16s\n",
      "H  180   191                       0.0000031    0.00000  96.3%   238   16s\n",
      "H  253   255                       0.0000031    0.00000  96.3%   200   18s\n",
      "   308   355    0.00000   84  124    0.00000    0.00000  96.3%   180   20s\n",
      "H  330   355                       0.0000030    0.00000  96.2%   173   20s\n",
      "H  342   355                       0.0000030    0.00000  96.2%   170   20s\n",
      "H  437   488                       0.0000029    0.00000  96.1%   149   22s\n",
      "H  467   488                       0.0000029    0.00000  96.1%   144   22s\n",
      "H  479   488                       0.0000029    0.00000  96.1%   142   22s\n",
      "H  506   566                       0.0000028    0.00000  96.0%   137   23s\n",
      "   652   726    0.00000  176  108    0.00000    0.00000  96.0%   119   25s\n",
      "H  854   831                       0.0000027    0.00000  95.8%   101   27s\n",
      "   903   848    0.00000   12  112    0.00000    0.00000  95.8%   101   30s\n",
      "H  909   842                       0.0000027    0.00000  95.8%   103   30s\n",
      "H  998   888                       0.0000026    0.00000  95.7%   111   34s\n",
      "H  998   881                       0.0000026    0.00000  95.6%   111   34s\n",
      "  1001   928    0.00000   36  115    0.00000    0.00000  95.6%   112   35s\n",
      "  1125  1004    0.00000   48  117    0.00000    0.00000  95.6%   115   40s\n",
      "  1128  1009    0.00000   14  106    0.00000    0.00000  95.6%   125   46s\n",
      "  1130  1013    0.00000   15  106    0.00000    0.00000  95.6%   125   50s\n",
      "  1142  1025    0.00000   17  116    0.00000    0.00000  95.6%   144   55s\n",
      "  1150  1029    0.00000   17  113    0.00000    0.00000  95.6%   149   60s\n",
      "\n",
      "Explored 1157 nodes (183184 simplex iterations) in 60.03 seconds (55.43 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 2.60336e-06 2.64236e-06 2.6965e-06 ... 3.00583e-06\n",
      "\n",
      "Time limit reached\n",
      "Best objective 2.603363868828e-06, best bound 1.140279224882e-07, gap 95.6200%\n"
     ]
    }
   ],
   "source": [
    "# # CARD\n",
    "beta_card = card(X_train, y_train, kact=10, time_limit=60)\n",
    "non_negative_count = np.sum(beta_card > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CARD\n",
    "beta_card_50 = card(X_train, y_train, kact=10, time_limit=60, seed=50)\n",
    "beta_card_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we checked if there are differnet seed for model, there is different beta(weight of portfolio)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALASSO Algorithm\n",
    "- make initial beta using OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alasso(X, y, kact, initial_beta=None, nu=1, tol=1e-10000, time_limit = 1200):\n",
    "    n, p = X.shape    \n",
    "    # If no initial beta is provided, use ordinary least squares estimate\n",
    "    if initial_beta is None:\n",
    "            init_m = gp.Model()\n",
    "            init_m.setParam('TimeLimit', time_limit)\n",
    "            initial_beta = init_m.addMVar(shape=p, lb=0, name=\"initial_beta\")\n",
    "            init_objective = (1/n) * ((y - X @ initial_beta) @ (y - X @ initial_beta))\n",
    "            #objective 설정\n",
    "            init_m.setObjective(init_objective, GRB.MINIMIZE)\n",
    "            #constraint 1: full investment\n",
    "            init_m.addConstr(initial_beta.sum() == 1, name=\"c0\")\n",
    "            init_m.optimize()\n",
    "            initial_beta = initial_beta.X\n",
    "\n",
    "    # Calculate weights\n",
    "    weights = 1 / (np.abs(initial_beta) ** nu)\n",
    "    m = gp.Model()\n",
    "#     m.setParam('TimeLimit', time_limit)\n",
    "    beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "    z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "\n",
    "    objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + (weights @ beta)\n",
    "    #objective 설정에 penalty term이 추가됨\n",
    "    m.setObjective(objective, GRB.MINIMIZE)\n",
    "    #constraint 0: z의 설정 beta가 0이 아니면 1로 설정\n",
    "    m.addConstr(beta <= z, name=\"c0\")\n",
    "    #constraint 1: full investment\n",
    "    m.addConstr(beta.sum() == 1, name=\"c1\")\n",
    "    #constraine 2: cardinality constraint\n",
    "    m.addConstr(z.sum() <= kact, name=\"c2\")\n",
    "    m.optimize()\n",
    "    return beta.X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 1200\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1 rows, 533 columns and 533 nonzeros\n",
      "Model fingerprint: 0xafe60f74\n",
      "Model has 142310 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 2e-02]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve time: 0.06s\n",
      "Presolved: 1 rows, 533 columns, 533 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " Free vars  : 250\n",
      " AA' NZ     : 3.138e+04\n",
      " Factor NZ  : 3.163e+04 (roughly 1 MB of memory)\n",
      " Factor Ops : 5.303e+06 (less than 1 second per iteration)\n",
      " Threads    : 4\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0  -4.81884870e+01  3.90837922e-05  5.31e+05 7.30e-04  1.00e+06     0s\n",
      "   1   1.22619857e+05 -1.23614435e+05  3.19e+03 2.11e-08  6.47e+03     0s\n",
      "   2   1.58201883e+04 -1.68301164e+04  8.54e+00 5.65e-11  7.75e+01     0s\n",
      "   3   2.14160788e+03 -3.43829506e+03  2.28e-01 1.51e-12  1.10e+01     0s\n",
      "   4   6.75573637e+01 -2.67205697e+03  2.28e-07 4.44e-15  5.14e+00     0s\n",
      "   5   3.03190845e+01 -3.29645961e+01  2.89e-11 1.08e-12  1.19e-01     0s\n",
      "   6   4.25235807e+00 -5.79126601e+00  4.22e-15 1.55e-15  1.88e-02     0s\n",
      "   7   6.02431888e-01 -7.16132894e-01  1.67e-15 5.00e-16  2.47e-03     0s\n",
      "   8   8.48735678e-02 -1.05061884e-01  6.66e-16 2.78e-16  3.56e-04     0s\n",
      "   9   1.19624208e-02 -1.52277980e-02  2.00e-15 2.78e-16  5.10e-05     0s\n",
      "  10   1.68964132e-03 -2.47776451e-03  3.33e-16 2.78e-17  7.82e-06     0s\n",
      "  11   2.41628618e-04 -4.38301464e-04  1.22e-15 2.78e-17  1.28e-06     0s\n",
      "  12   3.66416218e-05 -9.81849472e-05  2.44e-15 1.73e-18  2.53e-07     0s\n",
      "  13   6.20083150e-06 -1.36165007e-05  7.77e-16 2.60e-18  3.72e-08     0s\n",
      "  14   1.54759591e-06 -8.68188786e-06  1.11e-15 4.34e-19  1.92e-08     0s\n",
      "  15   3.68170307e-07 -1.28243948e-06  1.33e-15 1.08e-18  3.10e-09     0s\n",
      "  16   1.07679880e-07 -5.63919408e-07  2.44e-15 2.17e-19  1.26e-09     0s\n",
      "  17   3.33704411e-08 -4.09923355e-08  2.22e-16 2.17e-19  1.40e-10     0s\n",
      "  18   1.25536381e-08 -1.12168681e-08  1.33e-15 4.34e-19  4.46e-11     0s\n",
      "  19   6.56218526e-09  3.39431739e-09  3.33e-16 4.34e-19  5.94e-12     0s\n",
      "\n",
      "Barrier solved model in 19 iterations and 0.43 seconds (0.11 work units)\n",
      "Optimal objective 6.56218526e-09\n",
      "\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x98491e0e\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e+01, 1e+08]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 334.4266375\n",
      "Presolve time: 0.11s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 3.121419e+01, 5 iterations, 0.01 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      31.2141877   31.21419  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (5 simplex iterations) in 0.19 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 31.2142 334.427 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.121418772827e+01, best bound 3.121418772827e+01, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALASSO\n",
    "beta_alasso = alasso(X_train, y_train, kact=10)\n",
    "non_negative_count = np.sum(beta_alasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted LASSO- SLOPE\n",
    "detail is from Sparse index clones via the sorted l1-Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(X, y, kact, alpha=0.1, theta=0.1):\n",
    "    \"\"\"\n",
    "    Solve the SLOPE optimization problem using Gurobi with an activation constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like, shape (T, K)\n",
    "        The return matrix of benchmark constituents.\n",
    "    y : array-like, shape (T,)\n",
    "        The benchmark returns.\n",
    "    lambdas: regularization parameter vector for n features(followed instruction of experiment)\n",
    "    kact : int\n",
    "        Number of active variables (non-zero coefficients) allowed.\n",
    "    alpha : float, optional\n",
    "        Regularization parameter for the lambda sequence.\n",
    "    theta : float, optional\n",
    "        Decay rate for the lambda sequence.\n",
    "        \n",
    "    Returns:\n",
    "    w_opt : array-like, shape (K,)\n",
    "        Optimal weight vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dimensions\n",
    "    T, K = X.shape\n",
    "\n",
    "    # Lambda sequence\n",
    "    # ppf is inverse function of normal distribution CDF \n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * K))) for i in range(1, K + 1)])\n",
    "\n",
    "    # Initialize model\n",
    "    model = gp.Model(\"SLOPE\")\n",
    "    \n",
    "    # Variables\n",
    "    w = model.addVars(K, lb=0, name=\"w\")\n",
    "    z = model.addVars(K, lb=0, name=\"z\")\n",
    "    u = model.addVars(K, lb=0, name=\"u\")\n",
    "    abs_w = model.addVars(K, lb=0, name=\"abs_w\")\n",
    "\n",
    "    # Constraints for absolute values and sorting\n",
    "    model.addConstrs((z[i] >= w[i] for i in range(K)), \"abs_pos\")\n",
    "    model.addConstrs((z[i] >= -w[i] for i in range(K)), \"abs_neg\")\n",
    "    model.addConstrs((u[i] == gp.quicksum(z[j] for j in range(i+1)) for i in range(K)), \"sort\")\n",
    "    \n",
    "    # Activation constraint\n",
    "    model.addConstr(gp.quicksum(abs_w[i] >= 1e-5 for i in range(K)) <= kact, \"kact_limit\")\n",
    "\n",
    "    # Objective function\n",
    "    obj = (1/(2*T)) * gp.quicksum((y[t] - gp.quicksum(X[t,j]*w[j] for j in range(K)))**2 for t in range(T)) + \\\n",
    "          gp.quicksum(lambdas[i]*u[i] for i in range(K))\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Solve model\n",
    "    model.optimize()\n",
    "    \n",
    "    # Retrieve the optimal weights\n",
    "    w_opt = np.array([w[i].x for i in range(K)])\n",
    "    \n",
    "    return w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'gurobipy.LinExpr' and 'TempConstr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # CARD\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_slope_slc \u001b[38;5;241m=\u001b[39m \u001b[43mslope_slc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m non_negative_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(beta_slope_slc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m non_negative_count\n",
      "Cell \u001b[1;32mIn[71], line 43\u001b[0m, in \u001b[0;36mslope_slc\u001b[1;34m(X, y, kact, alpha, theta)\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39maddConstrs((u[i] \u001b[38;5;241m==\u001b[39m gp\u001b[38;5;241m.\u001b[39mquicksum(z[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msort\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Activation constraint\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m model\u001b[38;5;241m.\u001b[39maddConstr(\u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquicksum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabs_w\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m kact, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkact_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Objective function\u001b[39;00m\n\u001b[0;32m     46\u001b[0m obj \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mT)) \u001b[38;5;241m*\u001b[39m gp\u001b[38;5;241m.\u001b[39mquicksum((y[t] \u001b[38;5;241m-\u001b[39m gp\u001b[38;5;241m.\u001b[39mquicksum(X[t,j]\u001b[38;5;241m*\u001b[39mw[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K)))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T)) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     47\u001b[0m       gp\u001b[38;5;241m.\u001b[39mquicksum(lambdas[i]\u001b[38;5;241m*\u001b[39mu[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K))\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\gurobi.pxi:3843\u001b[0m, in \u001b[0;36mgurobipy.quicksum\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'gurobipy.LinExpr' and 'TempConstr'"
     ]
    }
   ],
   "source": [
    "# SLOPE\n",
    "beta_slope = slope(X_train, y_train, kact=10)\n",
    "non_negative_count = np.sum(beta_slope > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOPE-SLC\n",
    "1. Sorted LASSO의 변형 형태\n",
    "2. compute for each group the median partial correlation of consituents and keep only groups which are including 75th percent quantile for the equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_slc(X, y, lambdas, group_percentile=75, time_limit=1200):\n",
    "    \"\"\"\n",
    "    SLOPE-SLC algorithm implementation using Gurobi.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy.ndarray\n",
    "        Design matrix (n_samples, n_features)\n",
    "    y : numpy.ndarray\n",
    "        Response vector (n_samples,)\n",
    "    lambdas : numpy.ndarray\n",
    "        Regularization parameter vector (n_features,)\n",
    "    group_percentile : float\n",
    "        Percentile to select important groups (75 for equity, 25 for hedge funds)\n",
    "    time_limit : int, optional\n",
    "        Time limit for the optimization solver in seconds, default is 1200 seconds.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray\n",
    "        Estimated coefficients (n_features,)\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "\n",
    "    # Create a Gurobi model\n",
    "    m = gp.Model()\n",
    "    m.setParam('TimeLimit', time_limit)\n",
    "\n",
    "    # Define variables\n",
    "    beta = m.addMVar(shape=p, lb=-GRB.INFINITY, name=\"beta\")\n",
    "    abs_beta = m.addMVar(shape=p, lb=0, name=\"abs_beta\")\n",
    "\n",
    "    # Objective function: 1/2 ||y - X @ beta||^2 + sum(lambda_i * abs(beta)_i)\n",
    "    residuals = y - X @ beta\n",
    "    obj = (1/2) * (residuals @ residuals) + lambdas @ abs_beta\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    # 1. abs_beta >= beta\n",
    "    m.addConstr(abs_beta >= beta, name=\"abs_beta_pos\")\n",
    "    # 2. abs_beta >= -beta\n",
    "    m.addConstr(abs_beta >= -beta, name=\"abs_beta_neg\")\n",
    "\n",
    "    # Optimize the model\n",
    "    m.optimize()\n",
    "\n",
    "    # Extract the solution\n",
    "    beta_opt = beta.X\n",
    "\n",
    "    # Calculate partial correlations\n",
    "    residuals = y - X @ beta_opt\n",
    "    partial_correlations = np.array([np.dot(X[:, i], residuals) for i in range(p)])\n",
    "\n",
    "    # Group selection based on percentile\n",
    "    threshold = np.percentile(np.abs(partial_correlations), group_percentile)\n",
    "    important_groups = np.abs(partial_correlations) >= threshold\n",
    "\n",
    "    # Keep only the most important groups and set others to zero\n",
    "    beta_opt[~important_groups] = 0\n",
    "\n",
    "    # Rescale the remaining coefficients so that they sum up to 1\n",
    "    if np.sum(beta_opt) != 0:\n",
    "        beta_opt = beta_opt / np.sum(beta_opt)\n",
    "\n",
    "    return beta_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLOPE-SLC\n",
    "beta_slope_slc = slope_slc(X_train, y_train, kact=10)\n",
    "non_negative_count = np.sum(beta_slope_slc > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSW_LASSO\n",
    "detail is from High-dimensional Sprase index tracking based on a multi-step coonvex optimization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msw_lasso(X, y, kact, max_iter=100, tol=1e-4, penalty='MCP', a=3.7):\n",
    "    n, p = X.shape\n",
    "    weights = np.ones(p)\n",
    "    \n",
    "    def p_lambda(beta_j, lam, a):\n",
    "        if penalty == 'MCP':\n",
    "            return lam * beta_j - (beta_j**2) / (2 * a) if beta_j <= a * lam else (a * lam**2) / 2\n",
    "        elif penalty == 'SCAD':\n",
    "            if beta_j <= lam:\n",
    "                return lam * beta_j\n",
    "            elif beta_j <= a * lam:\n",
    "                return (-beta_j**2 + 2 * a * lam * beta_j - lam**2) / (2 * (a - 1))\n",
    "            else:\n",
    "                return (a + 1) * lam**2 / 2\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        m = gp.Model()\n",
    "        beta = m.addMVar(shape=p, lb=0, name=\"beta\")\n",
    "        z = m.addMVar(shape=p, vtype=GRB.BINARY, name=\"z\")\n",
    "        objective = (1/n) * ((y - X @ beta) @ (y - X @ beta)) + weights @ beta\n",
    "        m.setObjective(objective, GRB.MINIMIZE)\n",
    "        m.addConstr(beta.sum() == 1, name=\"c0\")\n",
    "        m.addConstr(z.sum() <= kact, name=\"c1\")\n",
    "        m.addConstr(beta >= 0, name=\"c2\")\n",
    "        m.optimize()\n",
    "        \n",
    "        beta_value = beta.X\n",
    "        new_weights = np.array([abs(p_lambda(beta_value[j], 1, a)) for j in range(p)])\n",
    "        \n",
    "        if np.linalg.norm(new_weights - weights) < tol:\n",
    "            break\n",
    "        weights = new_weights\n",
    "    \n",
    "    return beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msw_lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # CARD\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m beta_msw_lasso \u001b[38;5;241m=\u001b[39m \u001b[43mmsw_lasso\u001b[49m(X_train, y_train, kact\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m non_negative_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(beta_msw_lasso \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m non_negative_count\n",
      "\u001b[1;31mNameError\u001b[0m: name 'msw_lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# # msw_lasso\n",
    "beta_msw_lasso = msw_lasso(X_train, y_train, kact=10)\n",
    "non_negative_count = np.sum(beta_msw_lasso > 0)\n",
    "non_negative_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest\n",
    "## Experiment result \n",
    "- Turn over 비용\n",
    "- Tracking error(for out of sample)\n",
    "- Computing time(running time second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(X, y, beta):\n",
    "    tracking_error = np.sqrt(np.mean((y - X @ beta)**2))\n",
    "    turnover = np.sum(np.abs(beta[1:] - beta[:-1])) / len(beta)\n",
    "    return tracking_error, turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_backtest(stock_returns, stock_index, train_window, test_window, kact, lambdas):\n",
    "    results = {'CARD': [], 'ALASSO': [], 'SLOPE-SLC': [], 'MSW-LASSO': []}\n",
    "    n = len(stock_returns)\n",
    "    \n",
    "    for start in range(0, n - train_window - test_window + 1, test_window):\n",
    "        train_data = stock_returns.iloc[start:start + train_window]\n",
    "        test_data = stock_returns.iloc[start + train_window:start + train_window + test_window]\n",
    "    \n",
    "        # Filter out columns with NaN values in the current window\n",
    "        valid_assets_train = train_data.dropna(axis=1)\n",
    "        valid_assets_test = test_data.dropna(axis=1)\n",
    "        valid_assets = valid_assets_train.columns.intersection(valid_assets_test.columns)\n",
    "        \n",
    "        X_train = valid_assets_train[valid_assets].values\n",
    "        y_train = stock_index.iloc[start:start + train_window].values\n",
    "        \n",
    "        X_test = valid_assets_test[valid_assets].values\n",
    "        y_test = stock_index.iloc[start + train_window:start + train_window + test_window].values\n",
    "        # Skip if no valid assets are available\n",
    "        if X_train.shape[1] == 0 or X_test.shape[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        # # CARD\n",
    "        beta_card = card(X_train, y_train, kact)\n",
    "        te_card, to_card = evaluate_portfolio(X_test, y_test, beta_card)\n",
    "        results['CARD'].append({'date': stock_returns.index[start + train_window], 'te': te_card, 'to': to_card})\n",
    "        \n",
    "        # ALASSO\n",
    "        beta_alasso = alasso(X_train, y_train, kact)\n",
    "        te_alasso, to_alasso = evaluate_portfolio(X_test, y_test, beta_alasso)\n",
    "        results['ALASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_alasso, 'to': to_alasso})\n",
    "        \n",
    "        # # SLOPE-SLC\n",
    "        beta_slope_slc = slope_slc(X_train, y_train, kact, lambdas)\n",
    "        te_slope_slc, to_slope_slc = evaluate_portfolio(X_test, y_test, beta_slope_slc)\n",
    "        results['SLOPE-SLC'].append({'date': stock_returns.index[start + train_window], 'te': te_slope_slc, 'to': to_slope_slc})\n",
    "        \n",
    "        # # MSW-LASSO\n",
    "        beta_msw_lasso = msw_lasso(X_train, y_train, kact)\n",
    "        te_msw_lasso, to_msw_lasso = evaluate_portfolio(X_test, y_test, beta_msw_lasso)\n",
    "        results['MSW-LASSO'].append({'date': stock_returns.index[start + train_window], 'te': te_msw_lasso, 'to': to_msw_lasso})\n",
    "        \n",
    "        print(f\"Window ending {stock_returns.index[start + train_window].date()}:\")\n",
    "        print(f\"CARD: TE={te_card:.4f}, TO={to_card:.4f}\")\n",
    "        print(f\"ALASSO: TE={te_alasso:.4f}, TO={to_alasso:.4f}\")\n",
    "        print(f\"SLOPE-SLC: TE={te_slope_slc:.4f}, TO={to_slope_slc:.4f}\")\n",
    "        print(f\"MSW-LASSO: TE={te_msw_lasso:.4f}, TO={to_msw_lasso:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "kact = 10\n",
    "lambdas = np.linspace(0.1, 1, stock_returns.shape[1]-1)  # Adjust as needed\n",
    "train_window = 250\n",
    "test_window =21\n",
    "\n",
    "# DATA usage\n",
    "X = stock_returns.drop(columns=['^GSPC'])\n",
    "y = stock_returns['^GSPC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 1200\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 535 rows, 1066 columns and 2132 nonzeros\n",
      "Model fingerprint: 0x0f2c00e8\n",
      "Model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-06, 2e-02]\n",
      "  QObjective range [4e-09, 1e+04]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+01]\n",
      "Warning: Model contains large quadratic objective coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 0.0001483\n",
      "Presolve time: 0.05s\n",
      "Presolved: 535 rows, 1066 columns, 2132 nonzeros\n",
      "Presolved model has 142310 quadratic objective terms\n",
      "Variable types: 533 continuous, 533 integer (533 binary)\n",
      "\n",
      "Root relaxation: objective 1.140279e-07, 4355 iterations, 0.31 seconds (0.88 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0  106    0.00015    0.00000   100%     -    0s\n",
      "H    0     0                       0.0000175    0.00000  99.3%     -    0s\n",
      "H    0     0                       0.0000154    0.00000  99.3%     -    0s\n",
      "H    0     0                       0.0000128    0.00000  99.1%     -    0s\n",
      "     0     0    0.00000    0  106    0.00001    0.00000  99.1%     -    1s\n",
      "H    0     0                       0.0000055    0.00000  97.9%     -    1s\n",
      "H    0     0                       0.0000040    0.00000  97.1%     -    2s\n",
      "H    0     0                       0.0000036    0.00000  96.9%     -    3s\n",
      "     0     2    0.00000    0  106    0.00000    0.00000  96.9%     -    3s\n",
      "    11    16    0.00000    4  123    0.00000    0.00000  96.9%   583    5s\n",
      "    53    71    0.00000   14  124    0.00000    0.00000  96.9%   627   11s\n",
      "H   69    71                       0.0000035    0.00000  96.8%   539   11s\n",
      "H  100   135                       0.0000033    0.00000  96.6%   425   12s\n",
      "H  183   194                       0.0000033    0.00000  96.5%   285   14s\n",
      "   224   243    0.00000   63  132    0.00000    0.00000  96.5%   256   15s\n",
      "H  225   243                       0.0000032    0.00000  96.5%   255   15s\n",
      "H  226   243                       0.0000032    0.00000  96.4%   254   15s\n",
      "H  294   319                       0.0000030    0.00000  96.2%   215   16s\n",
      "H  375   407                       0.0000030    0.00000  96.2%   183   18s\n",
      "   461   520    0.00000  120  123    0.00000    0.00000  96.2%   160   20s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\ipykernel\\iostream.py:655\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    650\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread,\n\u001b[0;32m    651\u001b[0m                 msg,\n\u001b[0;32m    652\u001b[0m                 ident\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic,\n\u001b[0;32m    653\u001b[0m             )\n\u001b[1;32m--> 655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mint\u001b[39m]:  \u001b[38;5;66;03m# type:ignore[override]\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write to current stream after encoding if necessary\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    662\u001b[0m \n\u001b[0;32m    663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_header\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gurobipy.logcallbackstub'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zin\\Developer\\RankingMeetsIndexTracking\\.venv\\lib\\site-packages\\ipykernel\\iostream.py\", line 655, in write\n",
      "    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H  855   820                       0.0000029    0.00000  96.1%   106   27s\n",
      "H  893   840                       0.0000029    0.00000  96.1%   104   28s\n",
      "   974   915    0.00000   32  122    0.00000    0.00000  96.1%   106   30s\n",
      "H  995   888                       0.0000028    0.00000  95.9%   107   30s\n",
      "H 1006   878                       0.0000027    0.00000  95.8%   108   32s\n",
      "H 1008   873                       0.0000027    0.00000  95.7%   108   33s\n",
      "  1057   975    0.00000   59  123    0.00000    0.00000  95.7%   110   35s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform the rolling window backtest\n",
    "results = rolling_window_backtest(X, y, train_window, test_window, kact, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df_results = {key: pd.DataFrame(val).set_index('date') for key, val in results.items()}\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['te'], label=f'{key} Tracking Error')\n",
    "\n",
    "plt.title('Tracking Error Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tracking Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for key in df_results:\n",
    "    plt.plot(df_results[key]['to'], label=f'{key} Turnover')\n",
    "\n",
    "plt.title('Turnover Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Turnover')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMIT(Rank Meets Index tracking model)\n",
    "\n",
    "1. RMIT model makes n samples of B(weight of porfolio) -> using n Regression model(with diffent randomn state or epoch)\n",
    "2. for n num of B it test tracking error using train set(1month? or 12 month?)\n",
    "3. for n num of B it test tracking error using valid set(1 month)\n",
    "4. compare rank between 2,3 and add it's loss == rank Loss + origin loss \n",
    "5. repeat 1~3 which add rank loss, stop when beta does not change(small then epsilon) \n",
    "-> for last choose best beta(smallest beta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rank_loss(rank_type, train_errors, valid_errors):\n",
    "    if rank_type == \"pointwise\":\n",
    "        return np.sum(np.abs(train_errors - valid_errors))\n",
    "    elif rank_type == \"pairwise\":\n",
    "        return np.sum((train_errors - valid_errors)**2)\n",
    "    elif rank_type == \"listwise\":\n",
    "        return np.sum((np.argsort(train_errors) - np.argsort(valid_errors))**2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rank_type. Choose from 'pointwise', 'pairwise', 'listwise'.\")\n",
    "\n",
    "def optimize_portfolio(X_train, y_train, lambdas, kact, epsilon=1e-5):\n",
    "    T, K = X_train.shape\n",
    "\n",
    "    # Initialize model\n",
    "    model = gp.Model(\"SLOPE\")\n",
    "    \n",
    "    # Variables\n",
    "    w = model.addVars(K, lb=-GRB.INFINITY, name=\"w\")\n",
    "    z = model.addVars(K, lb=0, name=\"z\")\n",
    "    u = model.addVars(K, lb=0, name=\"u\")\n",
    "    abs_w = model.addVars(K, vtype=GRB.BINARY, name=\"abs_w\")\n",
    "\n",
    "    # Constraints for absolute values and sorting\n",
    "    model.addConstrs((z[i] >= w[i] for i in range(K)), \"abs_pos\")\n",
    "    model.addConstrs((z[i] >= -w[i] for i in range(K)), \"abs_neg\")\n",
    "    model.addConstrs((u[i] == gp.quicksum(z[j] for j in range(i+1)) for i in range(K)), \"sort\")\n",
    "    \n",
    "    # Activation constraint\n",
    "    model.addConstr(gp.quicksum(abs_w[i] for i in range(K)) <= kact, \"kact_limit\")\n",
    "\n",
    "    # Linking constraint for abs_w and w\n",
    "    model.addConstrs((abs_w[i] >= w[i] / 1e-5 for i in range(K)), \"link_pos\")\n",
    "    model.addConstrs((abs_w[i] >= -w[i] / 1e-5 for i in range(K)), \"link_neg\")\n",
    "    model.addConstrs((abs_w[i] <= 1 for i in range(K)), \"link_bin\")\n",
    "\n",
    "    # Objective function\n",
    "    obj = (1/(2*T)) * gp.quicksum((y_train[t] - gp.quicksum(X_train[t,j]*w[j] for j in range(K)))**2 for t in range(T)) + \\\n",
    "          gp.quicksum(lambdas[i]*u[i] for i in range(K))\n",
    "    \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    \n",
    "    # Solve model\n",
    "    model.optimize()\n",
    "    \n",
    "    # Retrieve the optimal weights\n",
    "    w_opt = np.array([w[i].x for i in range(K)])\n",
    "    \n",
    "    return w_opt\n",
    "\n",
    "def RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha=0.1, theta=0.1, epsilon=1e-5, n_models=10, max_iter=100):\n",
    "    T, K = X_train.shape\n",
    "    lambdas = np.array([alpha * norm.ppf(1 - (i * theta / (2 * K))) for i in range(1, K + 1)])\n",
    "\n",
    "    best_beta = None\n",
    "    best_loss = float('inf')\n",
    "    beta_change = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # 1. Generate n samples of B using n regression models\n",
    "        B_samples = []\n",
    "        for i in range(n_models):\n",
    "            model = Lasso(alpha=alpha, random_state=i)\n",
    "            model.fit(X_train, y_train)\n",
    "            B_samples.append(model.coef_)\n",
    "\n",
    "        # 2. Test tracking error using train set\n",
    "        train_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_train @ B\n",
    "            train_errors.append(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "        # 3. Test tracking error using valid set\n",
    "        valid_errors = []\n",
    "        for B in B_samples:\n",
    "            y_pred = X_valid @ B\n",
    "            valid_errors.append(mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "        # 4. Compare rank between train and valid errors and add its loss\n",
    "        rank_loss_value = rank_loss(rank_type, train_errors, valid_errors)\n",
    "\n",
    "        # Optimize with added rank loss\n",
    "        w_opt = optimize_portfolio(X_train, y_train, lambdas, kact, epsilon)\n",
    "        y_train_pred = X_train @ w_opt\n",
    "        origin_loss = mean_squared_error(y_train, y_train_pred)\n",
    "        total_loss = origin_loss + rank_loss_value\n",
    "\n",
    "        # 5. Repeat until beta does not change significantly\n",
    "        if best_loss - total_loss > epsilon:\n",
    "            best_loss = total_loss\n",
    "            best_beta = w_opt\n",
    "            beta_change = best_loss - total_loss\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_beta\n",
    "\n",
    "# Example usage:\n",
    "# X_train = np.array([...])  # Training set feature matrix\n",
    "# y_train = np.array([...])  # Training set target vector\n",
    "# X_valid = np.array([...])  # Validation set feature matrix\n",
    "# y_valid = np.array([...])  # Validation set target vector\n",
    "# kact = 10  # Number of active variables\n",
    "# rank_type = 'pointwise'  # Rank loss type ('pointwise', 'pairwise', 'listwise')\n",
    "# alpha = 0.1  # Regularization parameter\n",
    "# theta = 0.1  # Decay rate\n",
    "# epsilon = 1e-5  # Convergence threshold\n",
    "# n_models = 10  # Number of regression models\n",
    "# max_iter = 100  # Maximum number of iterations\n",
    "# best_beta = RMIT(X_train, y_train, X_valid, y_valid, kact, rank_type, alpha, theta, epsilon, n_models, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
